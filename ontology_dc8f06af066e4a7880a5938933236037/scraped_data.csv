Website,Title,Content
https://en.wikipedia.org/wiki/Chemistry,Chemistry,"
 Chemistry is the scientific study of the properties and behavior of matter.[1] It is a physical science under natural sciences that covers the elements that make up matter to the compounds made of atoms, molecules and ions: their composition, structure, properties, behavior and the changes they undergo during a reaction with other substances.[2][3][4][5] Chemistry also addresses the nature of chemical bonds in chemical compounds.
 In the scope of its subject, chemistry occupies an intermediate position between physics and biology.[6] It is sometimes called the central science because it provides a foundation for understanding both basic and applied scientific disciplines at a fundamental level.[7] For example, chemistry explains aspects of plant growth (botany), the formation of igneous rocks (geology), how atmospheric ozone is formed and how environmental pollutants are degraded (ecology), the properties of the soil on the moon (cosmochemistry), how medications work (pharmacology), and how to collect DNA evidence at a crime scene (forensics).
 Chemistry is a study that has existed since ancient times.[8] Over this time frame, it has evolved, and now chemistry encompasses various areas of specialisation, or subdisciplines, that continue to increase in number and interrelate to create further interdisciplinary fields of study. The applications of various fields of chemistry are used frequently for economic purposes in the chemical industry.
"
https://en.wikipedia.org/wiki/Matter,Matter,"
 In classical physics and general chemistry, matter is any substance that has mass and takes up space by having volume.[1] All everyday objects that can be touched are ultimately composed of atoms, which are made up of interacting subatomic particles, and in everyday as well as scientific usage, ""matter"" generally includes atoms and anything made up of them, and any particles (or combination of particles) that act as if they have both rest mass and volume. However it does not include massless particles such as photons, or other energy phenomena or waves such as light or heat.[1]: 21 [2] Matter exists in various states (also known as phases). These include classical everyday phases such as solid, liquid, and gas—for example water exists as ice, liquid water, and gaseous steam—but other states are possible, including plasma, Bose–Einstein condensates, fermionic condensates, and quark–gluon plasma.[3]
 Usually atoms can be imagined as a nucleus of protons and neutrons, and a surrounding ""cloud"" of orbiting electrons which ""take up space"".[4][5] However this is only somewhat correct, because subatomic particles and their properties are governed by their quantum nature, which means they do not act as everyday objects appear to act—they can act like waves as well as particles and they do not have well-defined sizes or positions. In the Standard Model of particle physics, matter is not a fundamental concept because the elementary constituents of atoms are quantum entities which do not have an inherent ""size"" or ""volume"" in any everyday sense of the word. Due to the exclusion principle and other fundamental interactions, some ""point particles"" known as fermions (quarks, leptons), and many composites and atoms, are effectively forced to keep a distance from other particles under everyday conditions; this creates the property of matter which appears to us as matter taking up space.
 For much of the history of the natural sciences people have contemplated the exact nature of matter. The idea that matter was built of discrete building blocks, the so-called particulate theory of matter, appeared in both ancient Greece and ancient India.[6] Early philosophers who proposed the particulate theory of matter include the ancient Indian philosopher Kanada (c. 6th–century BCE or after),[7] pre-Socratic Greek philosopher Leucippus (~490 BCE), and pre-Socratic Greek philosopher Democritus (~470–380 BCE).[8]
"
https://en.wikipedia.org/wiki/Atom,Atom,"
 An atom is a particle that consists of a nucleus of protons and neutrons surrounded by a cloud of electrons. The atom is the basic particle of the chemical elements, and the chemical elements are distinguished from each other by the number of protons that are in their atoms. For example, any atom that contains 11 protons is sodium, and any atom that contains 29 protons is copper. The number of neutrons defines the isotope of the element.
 Atoms are extremely small, typically around 100 picometers across. A human hair is about a million carbon atoms wide. This is smaller than the shortest wavelength of visible light, which means humans cannot see atoms with conventional microscopes. Atoms are so small that accurately predicting their behavior using classical physics is not possible due to quantum effects.
 More than 99.94% of an atom's mass is in the nucleus. The protons have a positive electric charge, the electrons have a negative electric charge, and the neutrons have no electric charge. If the number of protons and electrons are equal, then the atom is electrically neutral. If an atom has more or fewer electrons than protons, then it has an overall negative or positive charge, respectively—such atoms are called ions.
 The electrons of an atom are attracted to the protons in an atomic nucleus by the electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by the nuclear force. This force is usually stronger than the electromagnetic force that repels the positively charged protons from one another. Under certain circumstances, the repelling electromagnetic force becomes stronger than the nuclear force. In this case, the nucleus splits and leaves behind different elements. This is a form of nuclear decay.
 Atoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules or crystals. The ability of atoms to attach and detach is responsible for most of the physical changes observed in nature. Chemistry is the discipline that studies these changes.
"
https://en.wikipedia.org/wiki/Chemical_compound,Chemical compound,"
 A chemical compound is a chemical substance composed of many identical molecules (or molecular entities) containing atoms from more than one chemical element held together by chemical bonds. A molecule consisting of atoms of only one element is therefore not a compound. A compound can be transformed into a different substance by a chemical reaction, which may involve interactions with other substances. In this process, bonds between atoms may be broken and/or new bonds formed.
 There are four major types of compounds, distinguished by how the constituent atoms are bonded together. Molecular compounds are held together by covalent bonds; ionic compounds are held together by ionic bonds; intermetallic compounds are held together by metallic bonds; coordination complexes are held together by coordinate covalent bonds. Non-stoichiometric compounds form a disputed marginal case.
 A chemical formula specifies the number of atoms of each element in a compound molecule, using the standard chemical symbols with numerical subscripts. Many chemical compounds have a unique CAS number identifier assigned by the Chemical Abstracts Service. Globally, more than 350,000 chemical compounds (including mixtures of chemicals) have been registered for production and use.[1]
"
https://en.wikipedia.org/wiki/Molecule,Molecule,"
 
 A molecule is a group of two or more atoms held together by attractive forces known as chemical bonds; depending on context, the term may or may not include ions which satisfy this criterion.[4][5][6][7][8] In quantum physics, organic chemistry, and biochemistry, the distinction from ions is dropped and molecule is often used when referring to polyatomic ions.
 A molecule may be homonuclear, that is, it consists of atoms of one chemical element, e.g. two atoms in the oxygen molecule (O2); or it may be heteronuclear, a chemical compound composed of more than one element, e.g. water (two hydrogen atoms and one oxygen atom; H2O). In the kinetic theory of gases, the term molecule is often used for any gaseous particle regardless of its composition. This relaxes the requirement that a molecule contains two or more atoms, since the noble gases are individual atoms.[9] Atoms and complexes connected by non-covalent interactions, such as hydrogen bonds or ionic bonds, are typically not considered single molecules.[10]
 Concepts similar to molecules have been discussed since ancient times, but modern investigation into the nature of molecules and their bonds began in the 17th century. Refined over time by scientists such as Robert Boyle, Amedeo Avogadro, Jean Perrin, and Linus Pauling, the study of molecules is today known as molecular physics or molecular chemistry. 
"
https://en.wikipedia.org/wiki/Mole_(unit),Mole (unit),"The mole (symbol mol) is the unit of amount of substance in the International System of Units (SI).[1][2][3] The quantity amount of substance is a measure of how many elementary entities of a given substance are in an object or sample. 
 The mole is defined as exactly 6.02214076×1023 elementary entities. Depending on the nature of the substance, an elementary entity may be an atom, a molecule, an ion, an ion pair, or a subatomic particle such as a proton. For example, 10 moles of water (a chemical compound) and 10 moles of mercury (a chemical element) contain equal amounts of substance, and the mercury contains exactly one atom for each molecule of the water, despite the two substances having different volumes and different masses. The number of elementary entities in one mole is the Avogadro number, which is the approximate number of nucleons (protons or neutrons) in one gram of ordinary matter. 
 Before the 2019 redefinition of SI base units, the mole was defined as the number of elementary entities in 12 grams of carbon-12 (the most common isotope of carbon).
 The mole is widely used in chemistry as a convenient way to express amounts of reactants and amounts of products of chemical reactions. For example, the chemical equation 2H2 + O2 → 2H2O can be interpreted to mean that for each 2 mol dihydrogen (H2) and 1 mol dioxygen (O2) that react, 2 mol of water (H2O) form. The concentration of a solution is commonly expressed by its molar concentration, defined as the amount of dissolved substance per unit volume of solution, for which the unit typically used is moles per litre (mol/L).
 The term gram-molecule was formerly used to mean one mole of molecules, and gram-atom for one mole of atoms.[4] For example, 1 mole of MgBr2 is 1 gram-molecule of MgBr2 but 3 gram-atoms of MgBr2.[5][6]
"
https://en.wikipedia.org/wiki/Phase_(matter),Phase (matter),"In the physical sciences, a phase is a region of space (a thermodynamic system), throughout which all physical properties of a material are essentially uniform.[1][2]: 86 [3]: 3  Examples of physical properties include density, index of refraction, magnetization and chemical composition. A simple description is that a phase is a region of material that is chemically uniform, physically distinct, and (often) mechanically separable. In a system consisting of ice and water in a glass jar, the ice cubes are one phase, the water is a second phase, and the humid air is a third phase over the ice and water. The glass of the jar is another separate phase. (See state of matter § Glass)
 The term phase is sometimes used as a synonym for state of matter, but there can be several immiscible phases of the same state of matter. Also, the term phase is sometimes used to refer to a set of equilibrium states demarcated in terms of state variables such as pressure and temperature by a phase boundary on a phase diagram. Because phase boundaries relate to changes in the organization of matter, such as a change from liquid to solid or a more subtle change from one crystal structure to another, this latter usage is similar to the use of ""phase"" as a synonym for state of matter. However, the state of matter and phase diagram usages are not commensurate with the formal definition given above and the intended meaning must be determined in part from the context in which the term is used.
 Distinct phases may be described as different states of matter such as gas, liquid, solid, plasma or Bose–Einstein condensate. Useful mesophases between solid and liquid form other states of matter.
 Distinct phases may also exist within a given state of matter. As shown in the diagram for iron alloys, several phases exist for both the solid and liquid states. Phases may also be differentiated based on solubility as in polar (hydrophilic) or non-polar (hydrophobic). A mixture of water (a polar liquid) and oil (a non-polar liquid) will spontaneously separate into two phases. Water has a very low solubility (is insoluble) in oil, and oil has a low solubility in water. Solubility is the maximum amount of a solute that can dissolve in a solvent before the solute ceases to dissolve and remains in a separate phase. A mixture can separate into more than two liquid phases and the concept of phase separation extends to solids, i.e., solids can form solid solutions or crystallize into distinct crystal phases. Metal pairs that are mutually soluble can form alloys, whereas metal pairs that are mutually insoluble cannot.
 As many as eight immiscible liquid phases have been observed.[a] Mutually immiscible liquid phases are formed from water (aqueous phase), hydrophobic organic solvents, perfluorocarbons (fluorous phase), silicones, several different metals, and also from molten phosphorus. Not all organic solvents are completely miscible, e.g. a mixture of ethylene glycol and toluene may separate into two distinct organic phases.[b]
 Phases do not need to macroscopically separate spontaneously. Emulsions and colloids are examples of immiscible phase pair combinations that do not physically separate.
 Left to equilibration, many compositions will form a uniform single phase, but depending on the temperature and pressure even a single substance may separate into two or more distinct phases. Within each phase, the properties are uniform but between the two phases properties differ.
 Water in a closed jar with an air space over it forms a two-phase system. Most of the water is in the liquid phase, where it is held by the mutual attraction of water molecules. Even at equilibrium molecules are constantly in motion and, once in a while, a molecule in the liquid phase gains enough kinetic energy to break away from the liquid phase and enter the gas phase. Likewise, every once in a while a vapor molecule collides with the liquid surface and condenses into the liquid. At equilibrium, evaporation and condensation processes exactly balance and there is no net change in the volume of either phase.
 At room temperature and pressure, the water jar reaches equilibrium when the air over the water has a humidity of about 3%. This percentage increases as the temperature goes up. At 100 °C and atmospheric pressure, equilibrium is not reached until the air is 100% water. If the liquid is heated a little over 100 °C, the transition from liquid to gas will occur not only at the surface but throughout the liquid volume: the water boils.
 For a given composition, only certain phases are possible at a given temperature and pressure. The number and type of phases that will form is hard to predict and is usually determined by experiment. The results of such experiments can be plotted in phase diagrams.
 The phase diagram shown here is for a single component system. In this simple system, phases that are possible, depend only on pressure and temperature. The markings show points where two or more phases can co-exist in equilibrium. At temperatures and pressures away from the markings, there will be only one phase at equilibrium.
 In the diagram, the blue line marking the boundary between liquid and gas does not continue indefinitely, but terminates at a point called the critical point. As the temperature and pressure approach the critical point, the properties of the liquid and gas become progressively more similar. At the critical point, the liquid and gas become indistinguishable. Above the critical point, there are no longer separate liquid and gas phases: there is only a generic fluid phase referred to as a supercritical fluid. In water, the critical point occurs at around 647 K (374 °C or 705 °F) and 22.064 MPa.
 An unusual feature of the water phase diagram is that the solid–liquid phase line (illustrated by the dotted green line) has a negative slope. For most substances, the slope is positive as exemplified by the dark green line. This unusual feature of water is related to ice having a lower density than liquid water. Increasing the pressure drives the water into the higher density phase, which causes melting.
 Another interesting though not unusual feature of the phase diagram is the point where the solid–liquid phase line meets the liquid–gas phase line. The intersection is referred to as the triple point. At the triple point, all three phases can coexist.
 Experimentally, phase lines are relatively easy to map due to the interdependence of temperature and pressure that develops when multiple phases form. Gibbs' phase rule suggests that different phase are completely determined by these variables. Consider a test apparatus consisting of a closed and well insulated cylinder equipped with a piston. By controlling the temperature and the pressure, the system can be brought to any point on the phase diagram. From a point in the solid stability region (left side of diagram), increasing the temperature of the system would bring it into the region where a liquid or a gas is the equilibrium phase (depending on the pressure). If the piston is slowly lowered, the system will trace a curve of increasing temperature and pressure within the gas region of the phase diagram. At the point where gas begins to condense to liquid, the direction of the temperature and pressure curve will abruptly change to trace along the phase line until all of the water has condensed.
 Between two phases in equilibrium there is a narrow region where the properties are not that of either phase. Although this region may be very thin, it can have significant and easily observable effects, such as causing a liquid to exhibit surface tension. In mixtures, some components may preferentially move toward the interface. In terms of modeling, describing, or understanding the behavior of a particular system, it may be efficacious to treat the interfacial region as a separate phase.
 A single material may have several distinct solid states capable of forming separate phases. Water is a well-known example of such a material. For example, water ice is ordinarily found in the hexagonal form ice Ih, but can also exist as the cubic ice Ic, the rhombohedral ice II, and many other forms. Polymorphism is the ability of a solid to exist in more than one crystal form. For pure chemical elements, polymorphism is known as allotropy. For example, diamond, graphite, and fullerenes are different allotropes of carbon.
 When a substance undergoes a phase transition (changes from one state of matter to another) it usually either takes up or releases energy. For example, when water evaporates, the increase in kinetic energy as the evaporating molecules escape the attractive forces of the liquid is reflected in a decrease in temperature. The energy required to induce the phase transition is taken from the internal thermal energy of the water, which cools the liquid to a lower temperature; hence evaporation is useful for cooling. See Enthalpy of vaporization. The reverse process, condensation, releases heat. The heat energy, or enthalpy, associated with a solid to liquid transition is the enthalpy of fusion and that associated with a solid to gas transition is the enthalpy of sublimation.
 While phases of matter are traditionally defined for systems in thermal equilibrium, work on quantum many-body localized (MBL) systems has provided a framework for defining phases out of equilibrium. MBL phases never reach thermal equilibrium, and can allow for new forms of order disallowed in equilibrium via a phenomenon known as localization protected quantum order. The transitions between different MBL phases and between MBL and thermalizing phases are novel dynamical phase transitions whose properties are active areas of research.
"
https://en.wikipedia.org/wiki/Chemical_bond,Chemical bond,"
 A chemical bond is a lasting attraction between atoms or ions that enables the formation of molecules, crystals, and other structures. The bond may result from the electrostatic force between oppositely charged ions as in ionic bonds, or through the sharing of electrons as in covalent bonds. The strength of chemical bonds varies considerably; there are ""strong bonds"" or ""primary bonds"" such as covalent, ionic and metallic bonds, and ""weak bonds"" or ""secondary bonds"" such as dipole–dipole interactions, the London dispersion force, and hydrogen bonding.  
 Since opposite electric charges attract, the negatively charged electrons surrounding the nucleus and the positively charged protons within a nucleus attract each other. Because of the matter wave nature of electrons and their smaller mass, they occupy a much larger volume than the nuclei. Electrons shared between two nuclei will be attracted to both of them and occupy a larger space. Bonded nuclei maintain an optimal distance (the bond distance) balancing attractive and repulsive effects explained quantitatively by quantum theory.[1][2]
 The atoms in molecules, crystals, metals and other forms of matter are held together by chemical bonds, which determine the structure and properties of matter.
 All bonds can be described by quantum theory, but, in practice, simplified rules and other theories allow chemists to predict the strength, directionality, and polarity of bonds.[3] The octet rule and VSEPR theory are examples. More sophisticated theories are valence bond theory, which includes orbital hybridization[4] and resonance,[5] and molecular orbital theory[6] which includes the linear combination of atomic orbitals and ligand field theory. Electrostatics are used to describe bond polarities and the effects they have on chemical substances.
"
https://en.wikipedia.org/wiki/Energy,Energy,"
 In physics, energy (from Ancient Greek  ἐνέργεια (enérgeia) 'activity') is the quantitative property that is transferred to a body or to a physical system, recognizable in the performance of work and in the form of heat and light. Energy is a conserved quantity—the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The unit of measurement for energy in the International System of Units (SI) is the joule (J).
 Common forms of energy include the kinetic energy of a moving object, the potential energy stored by an object (for instance due to its position in a field), the elastic energy stored in a solid object, chemical energy associated with chemical reactions, the radiant energy carried by electromagnetic radiation, and the internal energy contained within a thermodynamic system. All living organisms constantly take in and release energy.
 Due to mass–energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. 
 Human civilization requires energy to function, which it gets from energy resources such as fossil fuels, nuclear fuel, or renewable energy. The Earth's climate and ecosystems processes are driven by the energy the planet receives from the Sun (although a small amount is also contributed by geothermal energy).
"
https://en.wikipedia.org/wiki/Chemical_reaction,Chemical reaction,"
 A chemical reaction is a process that leads to the chemical transformation of one set of chemical substances to another.[1] Classically, chemical reactions encompass changes that only involve the positions of electrons in the forming and breaking of chemical bonds between atoms, with no change to the nuclei (no change to the elements present), and can often be described by a chemical equation. Nuclear chemistry is a sub-discipline of chemistry that involves the chemical reactions of unstable and radioactive elements where both electronic and nuclear changes can occur.
 The substance (or substances) initially involved in a chemical reaction are called reactants or reagents. Chemical reactions are usually characterized by a chemical change, and they yield one or more products, which usually have properties different from the reactants. Reactions often consist of a sequence of individual sub-steps, the so-called elementary reactions, and the information on the precise course of action is part of the reaction mechanism. Chemical reactions are described with chemical equations, which symbolically present the starting materials, end products, and sometimes intermediate products and reaction conditions.
 Chemical reactions happen at a characteristic reaction rate at a given temperature and chemical concentration. Typically, reaction rates increase with increasing temperature because there is more thermal energy available to reach the activation energy necessary for breaking bonds between atoms.
 A reaction may be classified as redox in which oxidation and reduction occur or non-redox in which there is no oxidation and reduction occurring. Most simple redox reactions may be classified as a combination, decomposition, or single displacement reaction.
 Different chemical reactions are used during chemical synthesis in order to obtain the desired product. In biochemistry, a consecutive series of chemical reactions (where the product of one reaction is the reactant of the next reaction) form metabolic pathways. These reactions are often catalyzed by protein enzymes. Enzymes increase the rates of biochemical reactions, so that metabolic syntheses and decompositions impossible under ordinary conditions can occur at the temperature and concentrations present within a cell.
 The general concept of a chemical reaction has been extended to reactions between entities smaller than atoms, including nuclear reactions, radioactive decays and reactions between elementary particles, as described by quantum field theory.
"
https://en.wikipedia.org/wiki/History_of_chemistry,History of chemistry,"The history of chemistry represents a time span from ancient history to the present. By 1000 BC, civilizations used technologies that would eventually form the basis of the various branches of chemistry. Examples include the discovery of fire, extracting metals from ores, making pottery and glazes, fermenting beer and wine, extracting chemicals from plants for medicine and perfume, rendering fat into soap, making glass,
and making alloys like bronze.
 The protoscience of chemistry, alchemy, was unsuccessful in explaining the nature of matter and its transformations. However, by performing experiments and recording the results, alchemists set the stage for modern chemistry. While both alchemy and chemistry are concerned with matter and its transformations, chemists are seen as applying scientific method to their work.
 The history of chemistry is intertwined with the history of thermodynamics, especially through the work of Willard Gibbs.[1]
"
https://en.wikipedia.org/wiki/Atomic_theoryhttps://en.wikipedia.org/wiki/John_Daltonhttps://en.wikipedia.org/wiki/Niels_Bohr,Atomic theoryhttps://en.wikipedia.org/wiki/John Daltonhttps://en.wikipedia.org/wiki/Niels Bohr,
https://en.wikipedia.org/wiki/Bohr_model,Bohr model,"In atomic physics, the Bohr model or Rutherford–Bohr model of the atom, presented by Niels Bohr and Ernest Rutherford in 1913, consists of a small, dense nucleus surrounded by orbiting electrons. It is analogous to the structure of the Solar System, but with attraction provided by electrostatic force rather than gravity. In the history of atomic physics, it followed, and ultimately replaced, several earlier models, including Joseph Larmor's solar system model (1897), Jean Perrin's model (1901),[2] the cubical model (1902), Hantaro Nagaoka's Saturnian model (1904), the plum pudding model (1904), Arthur Haas's quantum model (1910), the Rutherford model (1911), and John William Nicholson's nuclear quantum model (1912). The improvement over the 1911 Rutherford model mainly concerned the new quantum mechanical interpretation introduced by Haas and Nicholson, but forsaking any attempt to explain radiation according to classical physics.
 The model's key success lay in explaining the Rydberg formula for hydrogen's spectral emission lines. While the Rydberg formula had been known experimentally, it did not gain a theoretical basis until the Bohr model was introduced. Not only did the Bohr model explain the reasons for the structure of the Rydberg formula, it also provided a justification for the fundamental physical constants that make up the formula's empirical results.
 The Bohr model is a relatively primitive model of the hydrogen atom, compared to the valence shell model. As a theory, it can be derived as a first-order approximation of the hydrogen atom using the broader and much more accurate quantum mechanics and thus may be considered to be an obsolete scientific theory. However, because of its simplicity, and its correct results for selected systems (see below for application), the Bohr model is still commonly taught to introduce students to quantum mechanics or energy level diagrams before moving on to the more accurate, but more complex, valence shell atom. A related quantum model was proposed by Arthur Erich Haas in 1910 but was rejected until the 1911 Solvay Congress where it was thoroughly discussed.[3] The quantum theory of the period between Planck's discovery of the quantum (1900) and the advent of a mature quantum mechanics (1925) is often referred to as the old quantum theory.
 In the early 20th century, experiments by Ernest Rutherford established that atoms consisted of a diffuse cloud of negatively charged electrons surrounding a small, dense, positively charged nucleus.[5] Given this experimental data, Rutherford naturally considered a planetary model of the atom, the Rutherford model of 1911. This had electrons orbiting a solar nucleus, but involved a technical difficulty: the laws of classical mechanics (i.e. the Larmor formula) predict that the electron will release electromagnetic radiation while orbiting a nucleus. Because the electron would lose energy, it would rapidly spiral inwards, collapsing into the nucleus on a timescale of around 16 picoseconds.[6] Rutherford's atom model is disastrous because it predicts that all atoms are unstable.[7] Also, as the electron spirals inward, the emission would rapidly increase in frequency due to the orbital period becoming shorter, resulting in electromagnetic radiation with a continuous spectrum. However, late 19th-century experiments with electric discharges had shown that atoms will only emit light (that is, electromagnetic radiation) at certain discrete frequencies. By the early twentieth century, it was expected that the atom would account for the spectral lines. In 1897, Lord Rayleigh analyzed the problem. By 1906, Rayleigh said, “the frequencies observed in the spectrum may not be frequencies of disturbance or of oscillation in the ordinary sense at all, but rather form an essential part of the original constitution of the atom as determined by conditions of stability.”[8][9]
 The outline of Bohr's atom came during the proceedings of the first Solvay Conference in 1911 on the subject of Radiation and Quanta, at which Bohr's mentor, Rutherford was present. Max Planck’s lecture ended with this remark: “... atoms or electrons subject to the molecular bond would obey the laws of quantum theory”.[10][11] Hendrik Lorentz in the discussion of Planck's lecture raised the question of the composition of the atom based on Thomson's model with a great portion of the discussion around the atomic model developed by Arthur Erich Haas. Lorentz explained that Planck's constant could be taken as determining the size of atoms, or that the size of atoms could be taken to determine Planck's constant.[12] Lorentz included comments regarding the emission and absorption of radiation concluding that “A stationary state will be established in which the number of electrons entering their spheres is equal to the number of those leaving them.”[3] In the discussion of what could regulate energy differences between atoms, Max Planck simply stated: “The intermediaries could be the electrons.”[13] The discussions outlined the need for the quantum theory to be included in the atom and the difficulties in an atomic theory. Planck in his talk said explicitly: “In order for an oscillator [molecule or atom] to be able to provide radiation in accordance with the equation, it is necessary to introduce into the laws of its operation, as we have already said at the beginning
of this Report, a particular physical hypothesis which is, on a fundamental point, in contradiction with classical Mechanics, explicitly or tacitly.”[14] Bohr's first paper on his atomic model quotes Planck almost word for word, saying: “Whatever the alteration in the laws of motion of the electrons may be, it seems necessary to introduce in the laws in question a quantity foreign to the classical electrodynamics, i. e. Planck's constant, or as it often is called the elementary quantum of action.” Bohr's footnote at the bottom of the page is to the French translation of the 1911 Solvay Congress proving he patterned his model directly on the proceedings and fundamental principles laid down by Planck, Lorentz, and the quantized Arthur Haas model of the atom which was mentioned seventeen times.[5]  Lorentz ended the discussion of Einstein's talk explaining: “The assumption that this energy must be a multiple of 



h
ν


{\displaystyle h\nu }

 leads to the following formula, where 



n


{\displaystyle n}

 is an integer: 



q

v

2


=
n
h
ν


{\displaystyle qv^{2}=nh\nu }

.”[15] Rutherford could have outlined these points to Bohr or given him a copy of the proceedings since he quoted from them and used them as a reference.[16] In a later interview, Bohr said it was very interesting to hear Rutherford's remarks about the Solvay Congress.[17] But Bohr said, “I saw the actual reports” of the Solvay Congress.[18]
 Then in 1912, Bohr came across the John William Nicholson theory of the atom model that quantized angular momentum as h/2π. According to a centennial celebration of the Bohr atom in Nature magazine, it was Nicholson who discovered that electrons radiate the spectral lines as they descend towards the nucleus and his theory was both nuclear and quantum.[11][19][20] Niels Bohr quoted him in his 1913 paper of the Bohr model of the atom.[5] The importance of the work of Nicholson's nuclear quantum atomic model on Bohr's model has been emphasized by many historians.[21][22][20][23]
 Next, Bohr was told by his friend, Hans Hansen, that the Balmer series is calculated using the Balmer formula, an empirical equation discovered by Johann Balmer in 1885 that described wavelengths of some spectral lines of hydrogen.[17][24] This was further generalized by Johannes Rydberg in 1888 resulting in what is now known as the Rydberg formula.
After this, Bohr declared, “everything became clear”.[24]
 To overcome the problems of Rutherford's atom, in 1913 Niels Bohr put forth three postulates that sum up most of his model:
 Other points are:
 Bohr's condition, that the angular momentum is an integer multiple of ħ was later reinterpreted in 1924 by de Broglie as a standing wave condition: the electron is described by a wave and a whole number of wavelengths must fit along the circumference of the electron's orbit:
 According to de Broglie's hypothesis, matter particles such as the electron behave as waves. The de Broglie wavelength of an electron is
 which implies that
 or
 where 



m
v
r


{\displaystyle mvr}

 is the angular momentum of the orbiting electron. Writing 



ℓ


{\displaystyle \ell }

 for this angular momentum, the previous equation becomes
 which is Bohr's second postulate.
 Bohr described angular momentum of the electron orbit as 1/2h while de Broglie's wavelength of λ = h/p described h divided by the electron momentum. In 1913, however, Bohr justified his rule by appealing to the correspondence principle, without providing any sort of wave interpretation. In 1913, the wave behavior of matter particles such as the electron was not suspected.
 In 1925, a new kind of mechanics was proposed, quantum mechanics, in which Bohr's model of electrons traveling in quantized orbits was extended into a more accurate model of electron motion. The new theory was proposed by Werner Heisenberg. Another form of the same theory, wave mechanics, was discovered by the Austrian physicist Erwin Schrödinger independently, and by different reasoning. Schrödinger employed de Broglie's matter waves, but sought wave solutions of a three-dimensional wave equation describing electrons that were constrained to move about the nucleus of a hydrogen-like atom, by being trapped by the potential of the positive nuclear charge.
 The Bohr model gives almost exact results only for a system where two charged points orbit each other at speeds much less than that of light. This not only involves one-electron systems such as the hydrogen atom, singly ionized helium, and doubly ionized lithium, but it includes positronium and Rydberg states of any atom where one electron is far away from everything else. It can be used for K-line X-ray transition calculations if other assumptions are added (see Moseley's law below). In high energy physics, it can be used to calculate the masses of heavy quark mesons.
 Calculation of the orbits requires two assumptions.
 If an electron in an atom is moving on an orbit with period T, classically the electromagnetic radiation will repeat itself every orbital period. If the coupling to the electromagnetic field is weak, so that the orbit doesn't decay very much in one cycle, the radiation will be emitted in a pattern which repeats every period, so that the Fourier transform will have frequencies which are only multiples of 1/T. This is the classical radiation law: the frequencies emitted are integer multiples of 1/T.
 In quantum mechanics, this emission must be in quanta of light, of frequencies consisting of integer multiples of 1/T, so that classical mechanics is an approximate description at large quantum numbers. This means that the energy level corresponding to a classical orbit of period 1/T must have nearby energy levels which differ in energy by h/T, and they should be equally spaced near that level,
 Bohr worried whether the energy spacing 1/T should be best calculated with the period of the energy state 




E

n




{\displaystyle E_{n}}

, or 




E

n
+
1




{\displaystyle E_{n+1}}

, or some average—in hindsight, this model is only the leading semiclassical approximation.
 Bohr considered circular orbits. Classically, these orbits must decay to smaller circles when photons are emitted. The level spacing between circular orbits can be calculated with the correspondence formula. For a hydrogen atom, the classical orbits have a period T determined by Kepler's third law to scale as r3/2. The energy scales as 1/r, so the level spacing formula amounts to
 It is possible to determine the energy levels by recursively stepping down orbit by orbit, but there is a shortcut.
 The angular momentum L of the circular orbit scales as 





r




{\displaystyle {\sqrt {r}}}

. The energy in terms of the angular momentum is then
 Assuming, with Bohr, that quantized values of L are equally spaced, the spacing between neighboring energies is
 This is as desired for equally spaced angular momenta. If one kept track of the constants, the spacing would be ħ, so the angular momentum should be an integer multiple of ħ,
 This is how Bohr arrived at his model.
 An electron in the lowest energy level of hydrogen (n = 1) therefore has about 13.6 eV less energy than a motionless electron infinitely far from the nucleus. The next energy level (n = 2) is −3.4 eV. The third (n = 3) is −1.51 eV, and so on. For larger values of n, these are also the binding energies of a highly excited atom with one electron in a large circular orbit around the rest of the atom. The hydrogen formula also coincides with the Wallis product.[27]
 The combination of natural constants in the energy formula is called the Rydberg energy (RE):
 This expression is clarified by interpreting it in combinations that form more natural units:
 Since this derivation is with the assumption that the nucleus is orbited by one electron, we can generalize this result by letting the nucleus have a charge q = Ze, where Z is the atomic number. This will now give us energy levels for hydrogenic (hydrogen-like) atoms, which can serve as a rough order-of-magnitude approximation of the actual energy levels. So for nuclei with Z protons, the energy levels are (to a rough approximation):
 The actual energy levels cannot be solved analytically for more than one electron (see n-body problem) because the electrons are not only affected by the nucleus but also interact with each other via the Coulomb Force.
 When Z = 1/α (Z ≈ 137), the motion becomes highly relativistic, and Z2 cancels the α2 in R; the orbit energy begins to be comparable to rest energy. Sufficiently large nuclei, if they were stable, would reduce their charge by creating a bound electron from the vacuum, ejecting the positron to infinity. This is the theoretical phenomenon of electromagnetic charge screening which predicts a maximum nuclear charge. Emission of such positrons has been observed in the collisions of heavy ions to create temporary super-heavy nuclei.[28]
 The Bohr formula properly uses the reduced mass of electron and proton in all situations, instead of the mass of the electron,
 However, these numbers are very nearly the same, due to the much larger mass of the proton, about 1836.1 times the mass of the electron, so that the reduced mass in the system is the mass of the electron multiplied by the constant 1836.1/(1+1836.1) = 0.99946. This fact was historically important in convincing Rutherford of the importance of Bohr's model, for it explained the fact that the frequencies of lines in the spectra for singly ionized helium do not differ from those of hydrogen by a factor of exactly 4, but rather by 4 times the ratio of the reduced mass for the hydrogen vs. the helium systems, which was much closer to the experimental ratio than exactly 4.
 For positronium, the formula uses the reduced mass also, but in this case, it is exactly the electron mass divided by 2. For any value of the radius, the electron and the positron are each moving at half the speed around their common center of mass, and each has only one fourth the kinetic energy. The total kinetic energy is half what it would be for a single electron moving around a heavy nucleus.
 The Rydberg formula, which was known empirically before Bohr's formula, is seen in Bohr's theory as describing the energies of transitions or quantum jumps between orbital energy levels. Bohr's formula gives the numerical value of the already-known and measured the Rydberg constant, but in terms of more fundamental constants of nature, including the electron's charge and the Planck constant.
 When the electron gets moved from its original energy level to a higher one, it then jumps back each level until it comes to the original position, which results in a photon being emitted. Using the derived formula for the different energy levels of hydrogen one may determine the wavelengths of light that a hydrogen atom can emit.
 The energy of a photon emitted by a hydrogen atom is given by the difference of two hydrogen energy levels:
 where nf is the final energy level, and ni is the initial energy level.
 Since the energy of a photon is
 the wavelength of the photon given off is given by
 This is known as the Rydberg formula, and the Rydberg constant R is RE/hc, or RE/2π in natural units. This formula was known in the nineteenth century to scientists studying spectroscopy, but there was no theoretical explanation for this form or a theoretical prediction for the value of R, until Bohr. In fact, Bohr's derivation of the Rydberg constant, as well as the concomitant agreement of Bohr's formula with experimentally observed spectral lines of the Lyman (nf =1), Balmer (nf =2), and Paschen (nf =3) series, and successful theoretical prediction of other lines not yet observed, was one reason that his model was immediately accepted.
 To apply to atoms with more than one electron, the Rydberg formula can be modified by replacing Z with Z − b or n with n − b where b is constant representing a screening effect due to the inner-shell and other electrons (see Electron shell and the later discussion of the ""Shell Model of the Atom"" below). This was established empirically before Bohr presented his model.
 Bohr's original three papers in 1913 described mainly the electron configuration in lighter elements. Bohr called his electron shells, “rings” in 1913. Atomic orbitals within shells did not exist at the time of his planetary model. Bohr explains in Part 3 of his famous 1913 paper that the maximum electrons in a shell is eight, writing: “We see, further, that a ring of n electrons cannot rotate in a single ring round a nucleus of charge ne unless n < 8.” For smaller atoms, the electron shells would be filled as follows: “rings of electrons will only join together if they contain equal numbers of electrons; and that accordingly the numbers of electrons on inner rings will only be 2, 4, 8”. However, in larger atoms the innermost shell would contain eight electrons, “on the other hand, the periodic system of the elements strongly suggests that already in neon N = 10 an inner ring of eight electrons will occur”. Bohr wrote ""From the above we are led to the following possible scheme for the arrangement of the electrons in light atoms:""[29][30][4][16]
 In Bohr's third 1913 paper Part III called ""Systems Containing Several Nuclei"", he says that two atoms form molecules on a symmetrical plane and he reverts to describing hydrogen.[31] The 1913 Bohr model did not discuss higher elements in detail and John William Nicholson was one of the first to prove in 1914 that it couldn't work for lithium, but was an attractive theory for hydrogen and ionized helium.[16][32]
 In 1921, following the work of chemists and others involved in work on the periodic table, Bohr extended the model of hydrogen to give an approximate model for heavier atoms. This gave a physical picture that reproduced many known atomic properties for the first time although these properties were proposed contemporarily with the identical work of chemist Charles Rugeley Bury[4][33]
 Bohr's partner in research during 1914 to 1916 was Walther Kossel who corrected Bohr's work to show that electrons interacted through the outer rings, and Kossel called the rings: “shells.”[34][35] Irving Langmuir is credited with the first viable arrangement of electrons in shells with only two in the first shell and going up to eight in the next according to the octet rule of 1904, although Kossel had already predicted a maximum of eight per shell in 1916.[36] Heavier atoms have more protons in the nucleus, and more electrons to cancel the charge. Bohr took from these chemists the idea that each discrete orbit could only hold a certain number of electrons. Per Kossel, after that the orbit is full, the next level would have to be used.[4] This gives the atom a shell structure designed by Kossel, Langmuir, and Bury, in which each shell corresponds to a Bohr orbit.
 This model is even more approximate than the model of hydrogen, because it treats the electrons in each shell as non-interacting. But the repulsions of electrons are taken into account somewhat by the phenomenon of screening. The electrons in outer orbits do not only orbit the nucleus, but they also move around the inner electrons, so the effective charge Z that they feel is reduced by the number of the electrons in the inner orbit.
 For example, the lithium atom has two electrons in the lowest 1s orbit, and these orbit at Z = 2. Each one sees the nuclear charge of Z = 3 minus the screening effect of the other, which crudely reduces the nuclear charge by 1 unit. This means that the innermost electrons orbit at approximately 1/2 the Bohr radius. The outermost electron in lithium orbits at roughly the Bohr radius, since the two inner electrons reduce the nuclear charge by 2. This outer electron should be at nearly one Bohr radius from the nucleus. Because the electrons strongly repel each other, the effective charge description is very approximate; the effective charge Z doesn't usually come out to be an integer. But Moseley's law experimentally probes the innermost pair of electrons, and shows that they do see a nuclear charge of approximately Z − 1, while the outermost electron in an atom or ion with only one electron in the outermost shell orbits a core with effective charge Z − k where k is the total number of electrons in the inner shells.
 The shell model was able to qualitatively explain many of the mysterious properties of atoms which became codified in the late 19th century in the periodic table of the elements. One property was the size of atoms, which could be determined approximately by measuring the viscosity of gases and density of pure crystalline solids. Atoms tend to get smaller toward the right in the periodic table, and become much larger at the next line of the table. Atoms to the right of the table tend to gain electrons, while atoms to the left tend to lose them. Every element on the last column of the table is chemically inert (noble gas).
 In the shell model, this phenomenon is explained by shell-filling. Successive atoms become smaller because they are filling orbits of the same size, until the orbit is full, at which point the next atom in the table has a loosely bound outer electron, causing it to expand. The first Bohr orbit is filled when it has two electrons, which explains why helium is inert. The second orbit allows eight electrons, and when it is full the atom is neon, again inert. The third orbital contains eight again, except that in the more correct Sommerfeld treatment (reproduced in modern quantum mechanics) there are extra ""d"" electrons. The third orbit may hold an extra 10 d electrons, but these positions are not filled until a few more orbitals from the next level are filled (filling the n=3 d orbitals produces the 10 transition elements). The irregular filling pattern is an effect of interactions between electrons, which are not taken into account in either the Bohr or Sommerfeld models and which are difficult to calculate even in the modern treatment.
 Niels Bohr said in 1962: ""You see actually the Rutherford work was not taken seriously. We cannot understand today, but it was not taken seriously at all. There was no mention of it any place. The great change came from Moseley.""[37]
 In 1913, Henry Moseley found an empirical relationship between the strongest X-ray line emitted by atoms under electron bombardment (then known as the K-alpha line), and their atomic number Z. Moseley's empiric formula was found to be derivable from Rydberg's formula and later Bohr's formula (Moseley actually mentions only Ernest Rutherford and Antonius Van den Broek in terms of models as these had been published before Moseley's work and Moseley's 1913 paper was published the same month as the first Bohr model paper).[38] The two additional assumptions that [1] this X-ray line came from a transition between energy levels with quantum numbers 1 and 2, and [2], that the atomic number Z when used in the formula for atoms heavier than hydrogen, should be diminished by 1, to (Z − 1)2.
 Moseley wrote to Bohr, puzzled about his results, but Bohr was not able to help. At that time, he thought that the postulated innermost ""K"" shell of electrons should have at least four electrons, not the two which would have neatly explained the result. So Moseley published his results without a theoretical explanation.
 It was Walther Kossel in 1914 and in 1916 who explained that in the periodic table new elements would be created as electrons were added to the outer shell. In Kossel's paper, he writes: “This leads to the conclusion that the electrons, which are added further, should be put into concentric rings or shells, on each of which ... only a certain number of electrons—namely, eight in our case—should be arranged. As soon as one ring or shell is completed, a new one has to be started for the next element; the number of electrons, which are most easily accessible, and lie at the outermost periphery, increases again from element to element and, therefore, in the formation of each new shell the chemical periodicity is repeated.”[34][35] Later, chemist Langmuir realized that the effect was caused by charge screening, with an inner shell containing only 2 electrons. In his 1919 paper, Irving Langmuir postulated the existence of ""cells"" which could each only contain two electrons each, and these were arranged in ""equidistant layers”.
 In the Moseley experiment, one of the innermost electrons in the atom is knocked out, leaving a vacancy in the lowest Bohr orbit, which contains a single remaining electron. This vacancy is then filled by an electron from the next orbit, which has n=2. But the n=2 electrons see an effective charge of Z − 1, which is the value appropriate for the charge of the nucleus, when a single electron remains in the lowest Bohr orbit to screen the nuclear charge +Z, and lower it by −1 (due to the electron's negative charge screening the nuclear positive charge). The energy gained by an electron dropping from the second shell to the first gives Moseley's law for K-alpha lines,
 or
 Here, Rv = RE/h is the Rydberg constant, in terms of frequency equal to 3.28 x 1015 Hz. For values of Z between 11 and 31 this latter relationship had been empirically derived by Moseley, in a simple (linear) plot of the square root of X-ray frequency against atomic number (however, for silver, Z = 47, the experimentally obtained screening term should be replaced by 0.4). Notwithstanding its restricted validity,[39] Moseley's law not only established the objective meaning of atomic number, but as Bohr noted, it also did more than the Rydberg derivation to establish the validity of the Rutherford/Van den Broek/Bohr nuclear model of the atom, with atomic number (place on the periodic table) standing for whole units of nuclear charge. Van den Broek had published his model in January 1913 showing the periodic table was arranged according to charge while Bohr's atomic model was not published until July 1913.[40]
 The K-alpha line of Moseley's time is now known to be a pair of close lines, written as (Kα1 and Kα2) in Siegbahn notation.
 The Bohr model gives an incorrect value L=ħ for the ground state orbital angular momentum: The angular momentum in the true ground state is known to be zero from experiment.[41] Although mental pictures fail somewhat at these levels of scale, an electron in the lowest modern ""orbital"" with no orbital momentum, may be thought of as not to rotate ""around"" the nucleus at all, but merely to go tightly around it in an ellipse with zero area (this may be pictured as ""back and forth"", without striking or interacting with the nucleus). This is only reproduced in a more sophisticated semiclassical treatment like Sommerfeld's. Still, even the most sophisticated semiclassical model fails to explain the fact that the lowest energy state is spherically symmetric – it doesn't point in any particular direction.
 Nevertheless, in the modern fully quantum treatment in phase space, the proper deformation (careful full extension) of the semi-classical result adjusts the angular momentum value to the correct effective one.[42] As a consequence, the physical ground state expression is obtained through a shift of the vanishing quantum angular momentum expression, which corresponds to spherical symmetry.
 In modern quantum mechanics, the electron in hydrogen is a spherical cloud of probability that grows denser near the nucleus. The rate-constant of probability-decay in hydrogen is equal to the inverse of the Bohr radius, but since Bohr worked with circular orbits, not zero area ellipses, the fact that these two numbers exactly agree is considered a ""coincidence"". (However, many such coincidental agreements are found between the semiclassical vs. full quantum mechanical treatment of the atom; these include identical energy levels in the hydrogen atom and the derivation of a fine-structure constant, which arises from the relativistic Bohr–Sommerfeld model (see below) and which happens to be equal to an entirely different concept, in full modern quantum mechanics).
 The Bohr model also has difficulty with, or else fails to explain:
 Several enhancements to the Bohr model were proposed, most notably the Sommerfeld or Bohr–Sommerfeld models, which suggested that electrons travel in elliptical orbits around a nucleus instead of the Bohr model's circular orbits.[1] This model supplemented the quantized angular momentum condition of the Bohr model with an additional radial quantization condition, the Wilson–Sommerfeld quantization condition[43][44]
 where pr is the radial momentum canonically conjugate to the coordinate q, which is the radial position, and T is one full orbital period. The integral is the action of action-angle coordinates. This condition, suggested by the correspondence principle, is the only one possible, since the quantum numbers are adiabatic invariants.
 The Bohr–Sommerfeld model was fundamentally inconsistent and led to many paradoxes. The magnetic quantum number measured the tilt of the orbital plane relative to the xy plane, and it could only take a few discrete values. This contradicted the obvious fact that an atom could be turned this way and that relative to the coordinates without restriction. The Sommerfeld quantization can be performed in different canonical coordinates and sometimes gives different answers. The incorporation of radiation corrections was difficult, because it required finding action-angle coordinates for a combined radiation/atom system, which is difficult when the radiation is allowed to escape. The whole theory did not extend to non-integrable motions, which meant that many systems could not be treated even in principle. In the end, the model was replaced by the modern quantum-mechanical treatment of the hydrogen atom, which was first given by Wolfgang Pauli in 1925, using Heisenberg's matrix mechanics. The current picture of the hydrogen atom is based on the atomic orbitals of wave mechanics, which Erwin Schrödinger developed in 1926.
 However, this is not to say that the Bohr–Sommerfeld model was without its successes. Calculations based on the Bohr–Sommerfeld model were able to accurately explain a number of more complex atomic spectral effects. For example, up to first-order perturbations, the Bohr model and quantum mechanics make the same predictions for the spectral line splitting in the Stark effect. At higher-order perturbations, however, the Bohr model and quantum mechanics differ, and measurements of the Stark effect under high field strengths helped confirm the correctness of quantum mechanics over the Bohr model. The prevailing theory behind this difference lies in the shapes of the orbitals of the electrons, which vary according to the energy state of the electron.
 The Bohr–Sommerfeld quantization conditions lead to questions in modern mathematics. Consistent semiclassical quantization condition requires a certain type of structure on the phase space, which places topological limitations on the types of symplectic manifolds which can be quantized. In particular, the symplectic form should be the curvature form of a connection of a Hermitian line bundle, which is called a prequantization.
 Bohr also updated his model in 1922, assuming that certain numbers of electrons (for example, 2, 8, and 18) correspond to stable ""closed shells"".[45]
 Niels Bohr proposed a model of the atom and a model of the chemical bond. According to his model for a diatomic molecule, the electrons of the atoms of the molecule form a rotating ring whose plane is perpendicular to the axis of the molecule and equidistant from the atomic nuclei. The dynamic equilibrium of the molecular system is achieved through the balance of forces between the forces of attraction of nuclei to the plane of the ring of electrons and the forces of mutual repulsion of the nuclei. The Bohr model of the chemical bond took into account the Coulomb repulsion – the electrons in the ring are at the maximum distance from each other.[46][47]
"
https://en.wikipedia.org/wiki/Quantum_chemistry,Quantum chemistry,"Quantum chemistry, also called molecular quantum mechanics, is a branch of physical chemistry focused on the application of quantum mechanics to chemical systems, particularly towards the quantum-mechanical calculation of electronic contributions to physical and chemical properties of molecules, materials, and solutions at the atomic level. These calculations include systematically applied approximations intended to make calculations computationally feasible while still capturing as much information about important contributions to the computed wave functions as well as to observable properties such as structures, spectra, and thermodynamic properties. Quantum chemistry is also concerned with the computation of quantum effects on molecular dynamics and chemical kinetics.  
 Chemists rely heavily on spectroscopy through which information regarding the quantization of energy on a molecular scale can be obtained. Common methods are infra-red (IR) spectroscopy, nuclear magnetic resonance (NMR) spectroscopy, and scanning probe microscopy. Quantum chemistry may be applied to the prediction and verification of spectroscopic data as well as other experimental data. 
 Many quantum chemistry studies are focused on the electronic ground state and excited states of individual atoms and molecules as well as the study of reaction pathways and transition states that occur during chemical reactions. Spectroscopic properties may also be predicted. Typically, such studies assume the electronic wave function is adiabatically parameterized by the nuclear positions (i.e., the Born–Oppenheimer approximation). A wide variety of approaches are used, including semi-empirical methods, density functional theory, Hartree-Fock calculations, quantum Monte Carlo methods, and coupled cluster methods. 
 Understanding electronic structure and molecular dynamics through the development of computational solutions to the Schrödinger equation is a central goal of quantum chemistry. Progress in the field depends on overcoming several challenges, including the need to increase the accuracy of the results for small molecular systems, and to also increase the size of large molecules that can be realistically subjected to computation, which is limited by scaling considerations — the computation time increases as a power of the number of atoms. 
"
https://en.wikipedia.org/wiki/Biology,Biology,"
 Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]
 Biologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]
 Life on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.
"
https://en.wikipedia.org/wiki/Cell_(biology),Cell (biology),"
 The cell is the basic structural and functional unit of life forms. Every cell consists of a cytoplasm enclosed within a membrane, and contains many biomolecules such as proteins, DNA and RNA, as well as many small molecules of nutrients and metabolites.[1] The term comes from the Latin word cellula meaning 'small room'.[2]
 Cells can acquire specified function and carry out various tasks within the cell such as replication, DNA repair, protein synthesis, and motility. Cells are capable of specialization and mobility within the cell. Most cells are measured in micrometers due to their small size.
 Most plant and animal cells are only visible under a light microscope, with dimensions between 1 and 100 micrometres.[3] Electron microscopy gives a much higher resolution showing greatly detailed cell structure. Organisms can be classified as unicellular (consisting of a single cell such as bacteria) or multicellular (including plants and animals).[4] Most unicellular organisms are classed as microorganisms. The number of cells in plants and animals varies from species to species; it has been approximated that the human body contains an estimated 37 trillion (3.72×1013) cells.[5] The brain accounts for around 80 billion of these cells.[6]
 The study of cells and how they work has led to many other studies in related areas of biology, including: discovery of DNA, cancer systems biology, aging and developmental biology.
 Cell biology is the study of cells, which were discovered by Robert Hooke in 1665, who named them for their resemblance to cells inhabited by Christian monks in a monastery.[7][8] Cell theory, first developed in 1839 by Matthias Jakob Schleiden and Theodor Schwann, states that all organisms are composed of one or more cells, that cells are the fundamental unit of structure and function in all living organisms, and that all cells come from pre-existing cells.[9] Cells emerged on Earth about 4 billion years ago.[10][11][12][13]
"
https://en.wikipedia.org/wiki/Prokaryote,Prokaryote,"A prokaryote (/proʊˈkærioʊt, -ət/) is a single-celled organism that lacks a nucleus and other membrane-bound organelles.[1] The word prokaryote comes from the Greek πρό (pro, 'before') and κάρυον (karyon, 'nut' or 'kernel').[2][3] In the two-empire system arising from the work of Édouard Chatton, prokaryotes were classified within the empire Prokaryota.[4] But in the three-domain system, based upon molecular analysis, prokaryotes are divided into two domains: Bacteria (formerly Eubacteria) and Archaea (formerly Archaebacteria). Organisms with nuclei are placed in a third domain, Eukaryota.[5] In biological evolution, prokaryotes are deemed to have arisen before eukaryotes.
 Besides the absence of a nucleus, prokaryotes also lack mitochondria, or most of the other membrane-bound organelles that characterize the eukaryotic cell. It was once thought that prokaryotic cellular components within the cytoplasm were unenclosed, except for an outer cell membrane, but bacterial microcompartments, which are thought to be simple organelles enclosed in protein shells, have been discovered,[6][7] along with other prokaryotic organelles.[8] While being unicellular, some prokaryotes, such as cyanobacteria, may form large colonies. Others, such as myxobacteria, have multicellular stages in their life cycles.[9] Prokaryotes are asexual, reproducing without fusion of gametes, although horizontal gene transfer may take place.
 Molecular studies have provided insight into the evolution and interrelationships of the three domains of life.[10] The division between prokaryotes and eukaryotes reflects the existence of two very different levels of cellular organization; only eukaryotic cells have an enveloped nucleus that contains its chromosomal DNA, and other characteristic membrane-bound organelles including mitochondria. Distinctive types of prokaryotes include extremophiles and methanogens; these are common in some extreme environments.[1]
"
https://en.wikipedia.org/wiki/Eukaryote,Eukaryote,"
 Eukaryota, whose members are known as eukaryotes (/juːˈkærioʊts, -əts/), is a diverse domain of organisms whose cells have a nucleus. All animals, plants, fungi, and many unicellular organisms are eukaryotes. They constitute a major group of living things, along with the two groups of prokaryotes, the Bacteria and the Archaea.
 The eukaryotes emerged in the Archaea, possibly within the Asgard archaea. This implies that there are only two domains of life, Bacteria and Archaea, with eukaryotes incorporated among the Archaea. Eukaryotes represent a small minority of the number of organisms, but, due to their generally much larger size, their collective global biomass is about equal to that of prokaryotes. Eukaryotes emerged approximately 2.2 billion years ago, during the  Proterozoic eon, likely as flagellated cells. These were created by symbiogenesis between an anaerobic Asgard archaean and an aerobic proteobacterium, which formed the mitochondria. A second episode of symbiogenesis with a cyanobacterium created the plants, with chloroplasts. The oldest known eukaryote fossils, multicellular planktonic organisms belonging to the Gabonionta, were discovered in Gabon in 2023, dating back to 2.1 billion years ago.[5]
 Eukaryotic cells contain membrane-bound organelles such as the nucleus, the endoplasmic reticulum, and the Golgi apparatus. Eukaryotes may be either unicellular or multicellular. In comparison, prokaryotes are typically unicellular. Unicellular eukaryotes are sometimes called protists. Eukaryotes can reproduce both asexually through mitosis and sexually through meiosis and gamete fusion.
 Eukaryotes are organisms that range from microscopic single cells, such as picozoans under 3 micrometres across,[6] to animals like the blue whale, weighing up to 190 tonnes and measuring up to 33.6 metres (110 ft) long,[7] or plants like the coast redwood, up to 120 metres (390 ft) tall.[8] Many eukaryotes are unicellular; the informal grouping called protists includes many of these, with some multicellular forms like the giant kelp up to 200 feet (61 m) long.[9] The multicellular eukaryotes include the animals, plants, and fungi, but again, these groups too contain many unicellular species.[10] Eukaryotic cells are typically much larger than those of prokaryotes – the bacteria and the archaea – having a volume of around 10,000 times greater.[11][12] Eukaryotes represent a small minority of the number of organisms, but, as many of them are much larger, their collective global biomass is about equal to that of prokaryotes.[13]
 The eukaryotes are a diverse lineage, consisting mainly of microscopic organisms.[14] Multicellularity in some form has evolved independently at least 25 times within the eukaryotes.[15][16] Complex multicellular organisms, not counting the aggregation of amoebae to form slime molds, have evolved within only six eukaryotic lineages: animals, symbiomycotan fungi, brown algae, red algae, green algae, and land plants.[17] Eukaryotes are grouped by genomic similarities, so that groups often lack visible shared characteristics.[14]
 The defining feature of eukaryotes is that their cells have a nucleus. This gives them their name, from the Greek εὖ (eu, ""well"" or ""good"") and κάρυον (karyon, ""nut"" or ""kernel"", here meaning ""nucleus"").[18] Eukaryotic cells have a variety of internal membrane-bound structures, called organelles, and a cytoskeleton which defines the cell's organization and shape. The nucleus stores the cell's DNA, which is divided into linear bundles called chromosomes;[19] these are separated into two matching sets by a microtubular spindle during nuclear division, in the distinctively eukaryotic process of mitosis.[20]
 Eukaryotes differ from prokaryotes in multiple ways, with unique biochemical pathways such as sterane synthesis.[21] The eukaryotic signature proteins have no homology to proteins in other domains of life, but appear to be universal among eukaryotes. They include the proteins of the cytoskeleton, the complex transcription machinery, the membrane-sorting systems, the nuclear pore, and some enzymes in the biochemical pathways.[22]
 Eukaryote cells include a variety of membrane-bound structures, together forming the endomembrane system.[23] Simple compartments, called vesicles and vacuoles, can form by budding off other membranes. Many cells ingest food and other materials through a process of endocytosis, where the outer membrane invaginates and then pinches off to form a vesicle.[24] Some cell products can leave in a vesicle through exocytosis.[25]
 The nucleus is surrounded by a double membrane known as the nuclear envelope, with nuclear pores that allow material to move in and out.[26] Various tube- and sheet-like extensions of the nuclear membrane form the endoplasmic reticulum, which is involved in protein transport and maturation. It includes the rough endoplasmic reticulum where ribosomes are attached to synthesize proteins, which enter the interior space or lumen. Subsequently, they generally enter vesicles, which bud off from the smooth endoplasmic reticulum.[27] In most eukaryotes, these protein-carrying vesicles are released and further modified in stacks of flattened vesicles (cisternae), the Golgi apparatus.[28]
 Vesicles may be specialized; for instance, lysosomes contain digestive enzymes that break down biomolecules in the cytoplasm.[29]
 Mitochondria are organelles found in all but one eukaryote, Monocercomonoides, which has secondarily lost its mitochondria.[30] The mitochondrion is commonly called ""the powerhouse of the cell"",[31] for its function providing energy by oxidising sugars or fats to produce the energy store ATP.[32][33] Mitochondria have two surrounding membranes, each a phospholipid bi-layer; the inner of which is folded into invaginations called cristae where aerobic respiration takes place.[34]
 Mitochondria contain their own DNA, which has close structural similarities to bacterial DNA, and which encodes rRNA and tRNA genes that produce RNA which is closer in structure to bacterial RNA than to eukaryote RNA.[35]
 Some eukaryotes, such as the metamonads such as Giardia and Trichomonas, and the amoebozoan Pelomyxa, appear to lack mitochondria, but all have been found to contain mitochondrion-derived organelles, such as hydrogenosomes and mitosomes, and thus have lost their mitochondria secondarily.[30] They obtain energy by enzymatic action on nutrients absorbed from the environment. The metamonad Monocercomonoides has also acquired, by lateral gene transfer, a cytosolic sulfur mobilization system which provides the clusters of iron and sulfur required for protein synthesis. The normal mitochondrial iron-sulfur cluster pathway has been lost secondarily.[30][36]
 Plants and various groups of algae have plastids as well as mitochondria. Plastids, like mitochondria, have their own DNA and are developed from endosymbionts, in this case cyanobacteria. They usually take the form of chloroplasts which, like cyanobacteria, contain chlorophyll and produce organic compounds (such as glucose) through photosynthesis. Others are involved in storing food. Although plastids probably had a single origin, not all plastid-containing groups are closely related. Instead, some eukaryotes have obtained them from others through secondary endosymbiosis or ingestion.[37] The capture and sequestering of photosynthetic cells and chloroplasts, kleptoplasty, occurs in many types of modern eukaryotic organisms.[38][39]
 Many eukaryotes have long slender motile cytoplasmic projections, called flagella, or multiple shorter structures called cilia. These organelles are variously involved in movement, feeding, and sensation. They are composed mainly of tubulin, and are entirely distinct from prokaryotic flagella. They are supported by a bundle of microtubules arising from a centriole, characteristically arranged as nine doublets surrounding two singlets. Flagella may have hairs (mastigonemes), as in many Stramenopiles. Their interior is continuous with the cell's cytoplasm.[40][41]
 Microfilamental structures composed of actin and actin-binding proteins, including α-actinin, fimbrin, and filamin are present in submembranous cortical layers and bundles, as well. Motor proteins of microtubules, dynein and kinesin, and myosin of actin filaments, provide dynamic character of the network.[42][43]
 Centrioles are often present even in cells and groups that do not have flagella, but conifers and flowering plants have neither. They generally occur in groups that give rise to various microtubular roots. These form a primary component of the cytoskeletal structure, and are often assembled over the course of several cell divisions, with one flagellum retained from the parent and the other derived from it. Centrioles produce the spindle during nuclear division.[44]
 The cells of plants and algae, fungi and most chromalveolates, but not animals, have a cell wall, a layer outside the cell membrane, providing the cell with structural support, protection, and a filtering mechanism. The cell wall also prevents over-expansion when water enters the cell.[45]
 The major polysaccharides making up the primary cell wall of land plants are cellulose, hemicellulose, and pectin. The cellulose microfibrils are linked via hemicellulosic tethers to form the cellulose-hemicellulose network, which is embedded in the pectin matrix. The most common hemicellulose in the primary cell wall is xyloglucan.[46]
 Eukaryotes have a life cycle that involves sexual reproduction, alternating between a haploid phase, where only one copy of each chromosome is present in each cell and a diploid phase, with two copies of each chromosome in each cell. The diploid phase is formed by fusion of two haploid gametes, such as eggs and spermatozoa, to form a zygote; this may grow into a body, with its cells dividing by mitosis, and at some stage produce haploid gametes through meiosis, a division that reduces the number of chromosomes and creates genetic variability.[47] There is considerable variation in this pattern. Plants have both haploid and diploid multicellular phases.[48] Eukaryotes have lower metabolic rates and longer generation times than prokaryotes, because they are larger and therefore have a smaller surface area to volume ratio.[49]
 The evolution of sexual reproduction may be a primordial characteristic of eukaryotes. Based on a phylogenetic analysis, Dacks and Roger have proposed that facultative sex was present in the group's common ancestor.[50] A core set of genes that function in meiosis is present in both Trichomonas vaginalis and Giardia intestinalis, two organisms previously thought to be asexual.[51][52] Since these two species are descendants of lineages that diverged early from the eukaryotic evolutionary tree, core meiotic genes, and hence sex, were likely present in the common ancestor of eukaryotes.[51][52] Species once thought to be asexual, such as Leishmania parasites, have a sexual cycle.[53] Amoebae, previously regarded as asexual, are anciently sexual; present-day asexual groups likely arose recently.[54]
 In antiquity, the two lineages of animals and plants were recognized by Aristotle and Theophrastus. The lineages were given the taxonomic rank of Kingdom by Linnaeus in the 18th century. Though he included the fungi with plants with some reservations, it was later realized that they are quite distinct and warrant a separate kingdom.[55] The various single-cell eukaryotes were originally placed with plants or animals when they became known. In 1818, the German biologist Georg A. Goldfuss coined the word protozoa to refer to organisms such as ciliates,[56] and this group was expanded until Ernst Haeckel made it a kingdom encompassing all single-celled eukaryotes, the Protista, in 1866.[57][58][59] The eukaryotes thus came to be seen as four kingdoms:
 The protists were at that time thought to be ""primitive forms"", and thus an evolutionary grade, united by their primitive unicellular nature.[58] The disentanglement of the deep splits in the tree of life only really started with DNA sequencing, leading to a system of domains rather than kingdoms as top level rank being put forward by Carl Woese, Otto Kandler, and Mark Wheelis in 1990, uniting all the eukaryote kingdoms in the domain ""Eucarya"", stating however that ""'eukaryotes' will continue to be an acceptable common synonym"".[3][60] In 1996, the evolutionary biologist Lynn Margulis proposed to replace Kingdoms and Domains with ""inclusive"" names to create a ""symbiosis-based phylogeny"", giving the description ""Eukarya (symbiosis-derived nucleated organisms)"".[4]
 
 By 2014, a rough consensus started to emerge from the phylogenomic studies of the previous two decades.[10][61] The majority of eukaryotes can be placed in one of two large clades dubbed Amorphea (similar in composition to the unikont hypothesis) and the Diphoda (formerly bikonts), which includes plants and most algal lineages. A third major grouping, the Excavata, has been abandoned as a formal group as it is paraphyletic.[2] The proposed phylogeny below includes only one group of excavates (Discoba),[62] and incorporates the recent proposal that picozoans are close relatives of rhodophytes.[63] The Provora are a group of microbial predators discovered in 2022.[1] The Metamonada have been hard to place, being sister possibly to Discoba, possibly to Malawimonada.[14]
 
 The origin of the eukaryotic cell, also known as eukaryogenesis, is a milestone in the evolution of life, since eukaryotes include all complex cells and almost all multicellular organisms. The last eukaryotic common ancestor (LECA) is the hypothetical origin of all living eukaryotes,[65] and was most likely a biological population.[66] It is believed to have been a protist with a nucleus, at least one centriole and flagellum, facultatively aerobic mitochondria, sex (meiosis and syngamy), a dormant cyst with a cell wall of chitin and/or cellulose and peroxisomes.[67][68][69]
 An endosymbiotic union between a motile anaerobic archaean and an aerobic alphaproteobacterium gave rise to eukaryotes, with mitochondria. A second endosymbiosis with a cyanobacterium gave rise to the ancestor of plants, with chloroplasts.[64]
 The timing of the origin of eukaryotes is hard to determine; Knoll (2006) suggests they developed as much as 2.2 billion years ago. Some acritarchs are known from at least 1.65 billion years ago, and the possible alga Grypania has been found as far back as 2.1 billion years ago.[70][71] The ""problematic""[72] fossil Diskagma has been found in paleosols 2.2 billion years old.[72]
 Organized living structures described as ""large colonial organisms"" have been found in the black shales of the Palaeoproterozoic Francevillian B Formation, in Gabon, dated at 2.1 billion years old. Eukaryotic life could have evolved at that time.[73][5] Fossils that are clearly related to modern groups start appearing an estimated 1.2 billion years ago, in the form of red algae, though recent work suggests the existence of fossilized filamentous algae in the Vindhya basin dating back perhaps to 1.6 to 1.7 billion years ago.[74]
 The presence of steranes, eukaryotic-specific biomarkers, in Australian shales previously indicated that eukaryotes were present in these rocks dated at 2.7 billion years old,[21][75] but these Archaean biomarkers have been rebutted as later contaminants.[76] The oldest valid biomarker records are only around 800 million years old.[77] In contrast, a molecular clock analysis suggests the emergence of sterol biosynthesis as early as 2.3 billion years ago.[78] The nature of steranes as eukaryotic biomarkers is further complicated by the production of sterols by some bacteria.[79][80]
 Whenever their origins, eukaryotes may not have become ecologically dominant until much later; a massive increase in the zinc composition of marine sediments 800 million years ago has been attributed to the rise of substantial populations of eukaryotes, which preferentially consume and incorporate zinc relative to prokaryotes, approximately a billion years after their origin (at the latest).[81]
  This article incorporates public domain material from Science Primer. NCBI. Archived from the original on 8 December 2009.
"
https://en.wikipedia.org/wiki/Organism,Organism,"
 An organism (from Ancient Greek  ὄργανον (órganon) 'instrument, implement, tool', and  -ισμός (-ismós)) is any biological living system that functions as an individual life form.[1] All organisms are composed of cells (cell theory).[1] The idea of organism is based on the concept of minimal functional unit of life. Three traits have been proposed to play the main role in qualification as an organism:
 Organisms include multicellular animals, plants, and fungi; or unicellular microorganisms such as protists, bacteria, and archaea.[5] All types of organisms are capable of reproduction, growth and development, maintenance, and some degree of response to stimuli. Most multicellular organisms differentiate into specialized tissues and organs during their development.
 A unicellular organism may be either a prokaryote or a eukaryote. Prokaryotes are represented by two separate domains – bacteria and archaea. Eukaryotic organisms are characterized by the presence of a membrane-bound cell nucleus and contain additional membrane-bound compartments called organelles (such as mitochondria in animals and plants and plastids in plants and algae, all generally considered to be derived from endosymbiotic bacteria).[6] Fungi, animals and plants are examples of kingdoms of organisms within the eukaryotes.
 Estimates on the number of Earth's current species range from 2 million to 1 trillion,[7] of which over 1.7 million have been documented.[8] More than 99% of all species, amounting to over five billion species,[9] that ever lived are estimated to be extinct.[10][11]
 In 2016, a set of 355 genes from the last universal common ancestor (LUCA) of all organisms from Earth was identified.[12][13]
"
https://en.wikipedia.org/wiki/Mitochondrion,Mitochondrion,"
 A mitochondrion (/ˌmaɪtəˈkɒndriən/;[1] PL mitochondria) is an organelle found in the cells of most eukaryotes, such as animals, plants and fungi. Mitochondria have a double membrane structure and use aerobic respiration to generate adenosine triphosphate (ATP), which is used throughout the cell as a source of chemical energy.[2] They were discovered by Albert von Kölliker in 1857[3] in the voluntary muscles of insects. The term mitochondrion was coined by Carl Benda in 1898. The mitochondrion is popularly nicknamed the ""powerhouse of the cell"", a phrase coined by Philip Siekevitz in a 1957 article of the same name.[4]
 Some cells in some multicellular organisms lack mitochondria (for example, mature mammalian red blood cells). A large number of unicellular organisms, such as microsporidia, parabasalids and diplomonads, have reduced or transformed their mitochondria into other structures.[5] One eukaryote, Monocercomonoides, is known to have completely lost its mitochondria,[6] and one multicellular organism, Henneguya salminicola, is known to have retained mitochondrion-related organelles in association with a complete loss of their mitochondrial genome.[6][7][8]
 Mitochondria are commonly between 0.75 and 3 μm2 in cross section,[9] but vary considerably in size and structure. Unless specifically stained, they are not visible. In addition to supplying cellular energy, mitochondria are involved in other tasks, such as signaling, cellular differentiation, and cell death, as well as maintaining control of the cell cycle and cell growth.[10] Mitochondrial biogenesis is in turn temporally coordinated with these cellular processes.[11][12] Mitochondria have been implicated in several human disorders and conditions, such as mitochondrial diseases,[13] cardiac dysfunction,[14] heart failure[15] and autism.[16]
 The number of mitochondria in a cell can vary widely by organism, tissue, and cell type. A mature red blood cell has no mitochondria,[17] whereas a liver cell can have more than 2000.[18][19] The mitochondrion is composed of compartments that carry out specialized functions. These compartments or regions include the outer membrane, intermembrane space, inner membrane, cristae, and matrix.
 Although most of a eukaryotic cell's DNA is contained in the cell nucleus, the mitochondrion has its own genome (""mitogenome"") that is substantially similar to bacterial genomes.[20] This finding has led to general acceptance of the endosymbiotic hypothesis - that free-living prokaryotic ancestors of modern mitochondria permanently fused with eukaryotic cells in the distant past, evolving such that modern animals, plants, fungi, and other eukaryotes are able to respire to generate cellular energy.[21]
"
https://en.wikipedia.org/wiki/Plastid,Plastid,"
 The plastid (Greek: πλαστός; plastós: formed, molded – plural plastids) is a membrane-bound organelle[1] found in the cells of plants, algae, and some other eukaryotic organisms. They are considered to be intracellular endosymbiotic cyanobacteria. Examples include chloroplasts (used for photosynthesis), chromoplasts (used for pigment synthesis and storage), and leucoplasts (non-pigmented plastids that can sometimes differentiate).
 The event which led to permanent endosymbiosis in the Archaeplastida clade (of land plants, red algae, and green algae) probably occurred with a cyanobiont (a symbiotic cyanobacteria) related to the genus Gloeomargarita, around 1.5 billion years ago.[2][3] A later primary endosymbiosis event occurred in photosynthetic Paulinella amoeboids about 90–140 million years ago. This plastid belongs to the ""PS-clade"" (of the cyanobacteria genera Prochlorococcus and Synechococcus).[4][5] Secondary and tertiary endosymbiosis has also occurred, in a wide variety of organisms; additionally, some organisms sequester ingested plastids in a process that is known as kleptoplasty.
 A. F. W. Schimper was the first to name and provide a clear definition of plastids.[6][a] They often contain pigments used in photosynthesis, and the types of pigments in a plastid determine the cell's color. They are also the site of manufacture and storage of important chemical compounds used by the cells of autotrophic eukaryotes. They possess a double-stranded DNA molecule that is circular, like that of the circular chromosome of prokaryotic cells. Even in organisms where the plastids have lost their photosynthetic properties, the plastid is kept because of its essential role in the production of molecules like the isoprenoids.[8]
"
https://en.wikipedia.org/wiki/Cytoskeleton,Cytoskeleton,"The cytoskeleton is a complex, dynamic network of interlinking protein filaments present in the cytoplasm of all cells, including those of bacteria and archaea.[1] In eukaryotes, it extends from the cell nucleus to the cell membrane and is composed of similar proteins in the various organisms. It is composed of three main components, microfilaments, intermediate filaments and microtubules, and these are all capable of rapid growth or disassembly dependent on the cell's requirements.[2]
 A multitude of functions can be performed by the cytoskeleton. Its primary function is to give the cell its shape and mechanical resistance to deformation, and through association with extracellular connective tissue and other cells it stabilizes entire tissues.[3][4] The cytoskeleton can also contract, thereby deforming the cell and the cell's environment and allowing cells to migrate.[5] Moreover, it is involved in many cell signaling pathways and in the uptake of extracellular material (endocytosis),[6] the segregation of chromosomes during cellular division,[3] the cytokinesis stage of cell division,[7] as scaffolding to organize the contents of the cell in space[5] and in intracellular transport (for example, the movement of vesicles and organelles within the cell)[3] and can be a template for the construction of a cell wall.[3] Furthermore, it can form specialized structures, such as flagella, cilia, lamellipodia and podosomes. The structure, function and dynamic behavior of the cytoskeleton can be very different, depending on organism and cell type.[3][8][7] Even within one cell, the cytoskeleton can change through association with other proteins and the previous history of the network.[5]
 A large-scale example of an action performed by the cytoskeleton is muscle contraction. This is carried out by groups of highly specialized cells working together. A main component in the cytoskeleton that helps show the true function of this muscle contraction is the microfilament. Microfilaments are composed of the most abundant cellular protein known as actin.[9] During contraction of a muscle, within each muscle cell, myosin molecular motors collectively exert forces on parallel actin filaments. Muscle contraction starts from nerve impulses which then causes increased amounts of calcium to be released from the sarcoplasmic reticulum. Increases in calcium in the cytosol allows muscle contraction to begin with the help of two proteins, tropomyosin and troponin.[9] Tropomyosin inhibits the interaction between actin and myosin, while troponin senses the increase in calcium and releases the inhibition.[10] This action contracts the muscle cell, and through the synchronous process in many muscle cells, the entire muscle.
"
"https://en.wikipedia.org/wiki/Cell_wall,https://en.wikipedia.org/wiki/Cell_membrane","Cell wall,https://en.wikipedia.org/wiki/Cell membrane",
https://en.wikipedia.org/wiki/DNA,DNA,"
 
 Deoxyribonucleic acid (/diːˈɒksɪˌraɪboʊnjuːˌkliːɪk, -ˌkleɪ-/ (listen);[1] DNA) is a polymer composed of two polynucleotide chains that coil around each other to form a double helix. The polymer carries genetic instructions for the development, functioning, growth and reproduction of all known organisms and many viruses. DNA and ribonucleic acid (RNA) are nucleic acids. Alongside proteins, lipids and complex carbohydrates (polysaccharides), nucleic acids are one of the four major types of macromolecules that are essential for all known forms of life.
 The two DNA strands are known as polynucleotides as they are composed of simpler monomeric units called nucleotides.[2][3] Each nucleotide is composed of one of four nitrogen-containing nucleobases (cytosine [C], guanine [G], adenine [A] or thymine [T]), a sugar called deoxyribose, and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds (known as the phosphodiester linkage) between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. The nitrogenous bases of the two separate polynucleotide strands are bound together, according to base pairing rules (A with T and C with G), with hydrogen bonds to make double-stranded DNA. The complementary nitrogenous bases are divided into two groups, pyrimidines and purines. In DNA, the pyrimidines are thymine and cytosine; the purines are adenine and guanine.
 Both strands of double-stranded DNA store the same biological information. This information is replicated when the two strands separate. A large part of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences. The two strands of DNA run in opposite directions to each other and are thus antiparallel. Attached to each sugar is one of four types of nucleobases (or bases). It is the sequence of these four nucleobases along the backbone that encodes genetic information. RNA strands are created using DNA strands as a template in a process called transcription, where DNA bases are exchanged for their corresponding bases except in the case of thymine (T), for which RNA substitutes uracil (U).[4] Under the genetic code, these RNA strands specify the sequence of amino acids within proteins in a process called translation.
 Within eukaryotic cells, DNA is organized into long structures called chromosomes. Before typical cell division, these chromosomes are duplicated in the process of DNA replication, providing a complete set of chromosomes for each daughter cell. Eukaryotic organisms (animals, plants, fungi and protists) store most of their DNA inside the cell nucleus as nuclear DNA, and some in the mitochondria as mitochondrial DNA or in chloroplasts as chloroplast DNA.[5] In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm, in circular chromosomes. Within eukaryotic chromosomes, chromatin proteins, such as histones, compact and organize DNA. These compacting structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.
 DNA is a long polymer made from repeating units called nucleotides.[6][7] The structure of DNA is dynamic along its length, being capable of coiling into tight loops and other shapes.[8] In all species it is composed of two helical chains, bound to each other by hydrogen bonds. Both chains are coiled around the same axis, and have the same pitch of 34 ångströms (3.4 nm). The pair of chains have a radius of 10 Å (1.0 nm).[9] According to another study, when measured in a different solution, the DNA chain measured 22–26 Å (2.2–2.6 nm) wide, and one nucleotide unit measured 3.3 Å (0.33 nm) long.[10]
 DNA does not usually exist as a single strand, but instead as a pair of strands that are held tightly together.[9][11] These two long strands coil around each other, in the shape of a double helix. The nucleotide contains both a segment of the backbone of the molecule (which holds the chain together) and a nucleobase (which interacts with the other DNA strand in the helix). A nucleobase linked to a sugar is called a nucleoside, and a base linked to a sugar and to one or more phosphate groups is called a nucleotide. A biopolymer comprising multiple linked nucleotides (as in DNA) is called a polynucleotide.[12]
 The backbone of the DNA strand is made from alternating phosphate and sugar groups.[13] The sugar in DNA is 2-deoxyribose, which is a pentose (five-carbon) sugar. The sugars are joined by phosphate groups that form phosphodiester bonds between the third and fifth carbon atoms of adjacent sugar rings. These are known as the 3′-end (three prime end), and 5′-end (five prime end) carbons, the prime symbol being used to distinguish these carbon atoms from those of the base to which the deoxyribose forms a glycosidic bond.[11]
 Therefore, any DNA strand normally has one end at which there is a phosphate group attached to the 5′ carbon of a ribose (the 5′ phosphoryl) and another end at which there is a free hydroxyl group attached to the 3′ carbon of a ribose (the 3′ hydroxyl). The orientation of the 3′ and 5′ carbons along the sugar-phosphate backbone confers directionality (sometimes called polarity) to each DNA strand. In a nucleic acid double helix, the direction of the nucleotides in one strand is opposite to their direction in the other strand: the strands are antiparallel. The asymmetric ends of DNA strands are said to have a directionality of five prime end (5′ ), and three prime end (3′), with the 5′ end having a terminal phosphate group and the 3′ end a terminal hydroxyl group. One major difference between DNA and RNA is the sugar, with the 2-deoxyribose in DNA being replaced by the related pentose sugar ribose in RNA.[11]
 The DNA double helix is stabilized primarily by two forces: hydrogen bonds between nucleotides and base-stacking interactions among aromatic nucleobases.[15] The four bases found in DNA are adenine (A), cytosine (C), guanine (G) and thymine (T). These four bases are attached to the sugar-phosphate to form the complete nucleotide, as shown for adenosine monophosphate. Adenine pairs with thymine and guanine pairs with cytosine, forming A-T and G-C base pairs.[16][17]
 The nucleobases are classified into two types: the purines, A and G, which are fused five- and six-membered heterocyclic compounds, and the pyrimidines, the six-membered rings C and T.[11] A fifth pyrimidine nucleobase, uracil (U), usually takes the place of thymine in RNA and differs from thymine by lacking a methyl group on its ring. In addition to RNA and DNA, many artificial nucleic acid analogues have been created to study the properties of nucleic acids, or for use in biotechnology.[18]
 Modified bases occur in DNA. The first of these recognized was 5-methylcytosine, which was found in the genome of Mycobacterium tuberculosis in 1925.[19] The reason for the presence of these noncanonical bases in bacterial viruses (bacteriophages) is to avoid the restriction enzymes present in bacteria. This enzyme system acts at least in part as a molecular immune system protecting bacteria from infection by viruses.[20] Modifications of the bases cytosine and adenine, the more common and modified DNA bases, play vital roles in the epigenetic control of gene expression in plants and animals.[21]
 A number of noncanonical bases are known to occur in DNA.[22] Most of these are modifications of the canonical bases plus uracil.
 Twin helical strands form the DNA backbone. Another double helix may be found tracing the spaces, or grooves, between the strands. These voids are adjacent to the base pairs and may provide a binding site. As the strands are not symmetrically located with respect to each other, the grooves are unequally sized. The major groove is 22 ångströms (2.2 nm) wide, while the minor groove is 12 Å (1.2 nm) in width.[23] Due to the larger width of the major groove, the edges of the bases are more accessible in the major groove than in the minor groove. As a result, proteins such as transcription factors that can bind to specific sequences in double-stranded DNA usually make contact with the sides of the bases exposed in the major groove.[24] This situation varies in unusual conformations of DNA within the cell (see below), but the major and minor grooves are always named to reflect the differences in width that would be seen if the DNA was twisted back into the ordinary B form.
 In a DNA double helix, each type of nucleobase on one strand bonds with just one type of nucleobase on the other strand. This is called complementary base pairing. Purines form hydrogen bonds to pyrimidines, with adenine bonding only to thymine in two hydrogen bonds, and cytosine bonding only to guanine in three hydrogen bonds. This arrangement of two nucleotides binding together across the double helix (from six-carbon ring to six-carbon ring) is called a Watson-Crick base pair. DNA with high GC-content is more stable than DNA with low GC-content. A Hoogsteen base pair (hydrogen bonding the 6-carbon ring to the 5-carbon ring) is a rare variation of base-pairing.[25] As hydrogen bonds are not covalent, they can be broken and rejoined relatively easily. The two strands of DNA in a double helix can thus be pulled apart like a zipper, either by a mechanical force or high temperature.[26] As a result of this base pair complementarity, all the information in the double-stranded sequence of a DNA helix is duplicated on each strand, which is vital in DNA replication. This reversible and specific interaction between complementary base pairs is critical for all the functions of DNA in organisms.[7]
 
 As noted above, most DNA molecules are actually two polymer strands, bound together in a helical fashion by noncovalent bonds; this double-stranded (dsDNA) structure is maintained largely by the intrastrand base stacking interactions, which are strongest for G,C stacks. The two strands can come apart—a process known as melting—to form two single-stranded DNA (ssDNA) molecules. Melting occurs at high temperatures, low salt and high pH (low pH also melts DNA, but since DNA is unstable due to acid depurination, low pH is rarely used).
 The stability of the dsDNA form depends not only on the GC-content (% G,C basepairs) but also on sequence (since stacking is sequence specific) and also length (longer molecules are more stable). The stability can be measured in various ways; a common way is the melting temperature (also called Tm value), which is the temperature at which 50% of the double-strand molecules are converted to single-strand molecules; melting temperature is dependent on ionic strength and the concentration of DNA. As a result, it is both the percentage of GC base pairs and the overall length of a DNA double helix that determines the strength of the association between the two strands of DNA. Long DNA helices with a high GC-content have more strongly interacting strands, while short helices with high AT content have more weakly interacting strands.[27] In biology, parts of the DNA double helix that need to separate easily, such as the TATAAT Pribnow box in some promoters, tend to have a high AT content, making the strands easier to pull apart.[28]
 In the laboratory, the strength of this interaction can be measured by finding the melting temperature Tm necessary to break half of the hydrogen bonds. When all the base pairs in a DNA double helix melt, the strands separate and exist in solution as two entirely independent molecules. These single-stranded DNA molecules have no single common shape, but some conformations are more stable than others.[29]
 In humans, the total female diploid nuclear genome per cell extends for 6.37 Gigabase pairs (Gbp), is 208.23 cm long and weighs 6.51 picograms (pg).[30] Male values are 6.27 Gbp, 205.00 cm, 6.41 pg.[30] Each DNA polymer can contain hundreds of millions of nucleotides, such as in chromosome 1. Chromosome 1 is the largest human chromosome with approximately 220 million base pairs, and would be 85 mm long if straightened.[31]
 In eukaryotes, in addition to nuclear DNA, there is also mitochondrial DNA (mtDNA) which encodes certain proteins used by the mitochondria. The mtDNA is usually relatively small in comparison to the nuclear DNA. For example, the human mitochondrial DNA forms closed circular molecules, each of which contains 16,569[32][33] DNA base pairs,[34] with each such molecule normally containing a full set of the mitochondrial genes. Each human mitochondrion contains, on average, approximately 5 such mtDNA molecules.[34] Each human cell contains approximately 100 mitochondria, giving a total number of mtDNA molecules per human cell of approximately 500.[34] However, the amount of mitochondria per cell also varies by cell type, and an egg cell can contain 100,000 mitochondria, corresponding to up to 1,500,000 copies of the mitochondrial genome (constituting up to 90% of the DNA of the cell).[35]
 A DNA sequence is called a ""sense"" sequence if it is the same as that of a messenger RNA copy that is translated into protein.[36] The sequence on the opposite strand is called the ""antisense"" sequence. Both sense and antisense sequences can exist on different parts of the same strand of DNA (i.e. both strands can contain both sense and antisense sequences). In both prokaryotes and eukaryotes, antisense RNA sequences are produced, but the functions of these RNAs are not entirely clear.[37] One proposal is that antisense RNAs are involved in regulating gene expression through RNA-RNA base pairing.[38]
 A few DNA sequences in prokaryotes and eukaryotes, and more in plasmids and viruses, blur the distinction between sense and antisense strands by having overlapping genes.[39] In these cases, some DNA sequences do double duty, encoding one protein when read along one strand, and a second protein when read in the opposite direction along the other strand. In bacteria, this overlap may be involved in the regulation of gene transcription,[40] while in viruses, overlapping genes increase the amount of information that can be encoded within the small viral genome.[41]
 DNA can be twisted like a rope in a process called DNA supercoiling. With DNA in its ""relaxed"" state, a strand usually circles the axis of the double helix once every 10.4 base pairs, but if the DNA is twisted the strands become more tightly or more loosely wound.[42] If the DNA is twisted in the direction of the helix, this is positive supercoiling, and the bases are held more tightly together. If they are twisted in the opposite direction, this is negative supercoiling, and the bases come apart more easily. In nature, most DNA has slight negative supercoiling that is introduced by enzymes called topoisomerases.[43] These enzymes are also needed to relieve the twisting stresses introduced into DNA strands during processes such as transcription and DNA replication.[44]
 DNA exists in many possible conformations that include A-DNA, B-DNA, and Z-DNA forms, although only B-DNA and Z-DNA have been directly observed in functional organisms.[13] The conformation that DNA adopts depends on the hydration level, DNA sequence, the amount and direction of supercoiling, chemical modifications of the bases, the type and concentration of metal ions, and the presence of polyamines in solution.[45]
 The first published reports of A-DNA X-ray diffraction patterns—and also B-DNA—used analyses based on Patterson functions that provided only a limited amount of structural information for oriented fibers of DNA.[46][47] An alternative analysis was proposed by Wilkins et al. in 1953 for the in vivo B-DNA X-ray diffraction-scattering patterns of highly hydrated DNA fibers in terms of squares of Bessel functions.[48] In the same journal, James Watson and Francis Crick presented their molecular modeling analysis of the DNA X-ray diffraction patterns to suggest that the structure was a double helix.[9]
 Although the B-DNA form is most common under the conditions found in cells,[49] it is not a well-defined conformation but a family of related DNA conformations[50] that occur at the high hydration levels present in cells. Their corresponding X-ray diffraction and scattering patterns are characteristic of molecular paracrystals with a significant degree of disorder.[51][52]
 Compared to B-DNA, the A-DNA form is a wider right-handed spiral, with a shallow, wide minor groove and a narrower, deeper major groove. The A form occurs under non-physiological conditions in partly dehydrated samples of DNA, while in the cell it may be produced in hybrid pairings of DNA and RNA strands, and in enzyme-DNA complexes.[53][54] Segments of DNA where the bases have been chemically modified by methylation may undergo a larger change in conformation and adopt the Z form. Here, the strands turn about the helical axis in a left-handed spiral, the opposite of the more common B form.[55] These unusual structures can be recognized by specific Z-DNA binding proteins and may be involved in the regulation of transcription.[56]
 For many years, exobiologists have proposed the existence of a shadow biosphere, a postulated microbial biosphere of Earth that uses radically different biochemical and molecular processes than currently known life. One of the proposals was the existence of lifeforms that use arsenic instead of phosphorus in DNA. A report in 2010 of the possibility in the bacterium GFAJ-1 was announced,[57][58] though the research was disputed,[58][59] and evidence suggests the bacterium actively prevents the incorporation of arsenic into the DNA backbone and other biomolecules.[60]
 At the ends of the linear chromosomes are specialized regions of DNA called telomeres. The main function of these regions is to allow the cell to replicate chromosome ends using the enzyme telomerase, as the enzymes that normally replicate DNA cannot copy the extreme 3′ ends of chromosomes.[62] These specialized chromosome caps also help protect the DNA ends, and stop the DNA repair systems in the cell from treating them as damage to be corrected.[63] In human cells, telomeres are usually lengths of single-stranded DNA containing several thousand repeats of a simple TTAGGG sequence.[64]
 These guanine-rich sequences may stabilize chromosome ends by forming structures of stacked sets of four-base units, rather than the usual base pairs found in other DNA molecules. Here, four guanine bases, known as a guanine tetrad, form a flat plate. These flat four-base units then stack on top of each other to form a stable G-quadruplex structure.[65] These structures are stabilized by hydrogen bonding between the edges of the bases and chelation of a metal ion in the centre of each four-base unit.[66] Other structures can also be formed, with the central set of four bases coming from either a single strand folded around the bases, or several different parallel strands, each contributing one base to the central structure.
 In addition to these stacked structures, telomeres also form large loop structures called telomere loops, or T-loops. Here, the single-stranded DNA curls around in a long circle stabilized by telomere-binding proteins.[67] At the very end of the T-loop, the single-stranded telomere DNA is held onto a region of double-stranded DNA by the telomere strand disrupting the double-helical DNA and base pairing to one of the two strands. This triple-stranded structure is called a displacement loop or D-loop.[65]
 In DNA, fraying occurs when non-complementary regions exist at the end of an otherwise complementary double-strand of DNA. However, branched DNA can occur if a third strand of DNA is introduced and contains adjoining regions able to hybridize with the frayed regions of the pre-existing double-strand. Although the simplest example of branched DNA involves only three strands of DNA, complexes involving additional strands and multiple branches are also possible.[68] Branched DNA can be used in nanotechnology to construct geometric shapes, see the section on uses in technology below.
 Several artificial nucleobases have been synthesized, and successfully incorporated in the eight-base DNA analogue named Hachimoji DNA. Dubbed S, B, P, and Z, these artificial bases are capable of bonding with each other in a predictable way (S–B and P–Z), maintain the double helix structure of DNA, and be transcribed to RNA. Their existence could be seen as an indication that there is nothing special about the four natural nucleobases that evolved on Earth.[69][70] On the other hand, DNA is tightly related to RNA which does not only act as a transcript of DNA but also performs as molecular machines many tasks in cells. For this purpose it has to fold into a structure. It has been shown that to allow to create all possible structures at least four bases are required for the corresponding RNA,[71] while a higher number is also possible but this would be against the natural principle of least effort.
 The phosphate groups of DNA give it similar acidic properties to phosphoric acid and it can be considered as a strong acid. It will be fully ionized at a normal cellular pH, releasing protons which leave behind negative charges on the phosphate groups. These negative charges protect DNA from breakdown by hydrolysis by repelling nucleophiles which could hydrolyze it.[72]
 Pure DNA extracted from cells forms white, stringy clumps.[73]
 The expression of genes is influenced by how the DNA is packaged in chromosomes, in a structure called chromatin. Base modifications can be involved in packaging, with regions that have low or no gene expression usually containing high levels of methylation of cytosine bases. DNA packaging and its influence on gene expression can also occur by covalent modifications of the histone protein core around which DNA is wrapped in the chromatin structure or else by remodeling carried out by chromatin remodeling complexes (see Chromatin remodeling). There is, further, crosstalk between DNA methylation and histone modification, so they can coordinately affect chromatin and gene expression.[74]
 For one example, cytosine methylation produces 5-methylcytosine, which is important for X-inactivation of chromosomes.[75] The average level of methylation varies between organisms—the worm Caenorhabditis elegans lacks cytosine methylation, while vertebrates have higher levels, with up to 1% of their DNA containing 5-methylcytosine.[76] Despite the importance of 5-methylcytosine, it can deaminate to leave a thymine base, so methylated cytosines are particularly prone to mutations.[77] Other base modifications include adenine methylation in bacteria, the presence of 5-hydroxymethylcytosine in the brain,[78] and the glycosylation of uracil to produce the ""J-base"" in kinetoplastids.[79][80]
 DNA can be damaged by many sorts of mutagens, which change the DNA sequence. Mutagens include oxidizing agents, alkylating agents and also high-energy electromagnetic radiation such as ultraviolet light and X-rays. The type of DNA damage produced depends on the type of mutagen. For example, UV light can damage DNA by producing thymine dimers, which are cross-links between pyrimidine bases.[82] On the other hand, oxidants such as free radicals or hydrogen peroxide produce multiple forms of damage, including base modifications, particularly of guanosine, and double-strand breaks.[83] A typical human cell contains about 150,000 bases that have suffered oxidative damage.[84] Of these oxidative lesions, the most dangerous are double-strand breaks, as these are difficult to repair and can produce point mutations, insertions, deletions from the DNA sequence, and chromosomal translocations.[85] These mutations can cause cancer. Because of inherent limits in the DNA repair mechanisms, if humans lived long enough, they would all eventually develop cancer.[86][87] DNA damages that are naturally occurring, due to normal cellular processes that produce reactive oxygen species, the hydrolytic activities of cellular water, etc., also occur frequently. Although most of these damages are repaired, in any cell some DNA damage may remain despite the action of repair processes. These remaining DNA damages accumulate with age in mammalian postmitotic tissues. This accumulation appears to be an important underlying cause of aging.[88][89][90]
 Many mutagens fit into the space between two adjacent base pairs, this is called intercalation. Most intercalators are aromatic and planar molecules; examples include ethidium bromide, acridines, daunomycin, and doxorubicin. For an intercalator to fit between base pairs, the bases must separate, distorting the DNA strands by unwinding of the double helix. This inhibits both transcription and DNA replication, causing toxicity and mutations.[91] As a result, DNA intercalators may be carcinogens, and in the case of thalidomide, a teratogen.[92] Others such as benzo[a]pyrene diol epoxide and aflatoxin form DNA adducts that induce errors in replication.[93] Nevertheless, due to their ability to inhibit DNA transcription and replication, other similar toxins are also used in chemotherapy to inhibit rapidly growing cancer cells.[94]
 DNA usually occurs as linear chromosomes in eukaryotes, and circular chromosomes in prokaryotes. The set of chromosomes in a cell makes up its genome; the human genome has approximately 3 billion base pairs of DNA arranged into 46 chromosomes.[95] The information carried by DNA is held in the sequence of pieces of DNA called genes. Transmission of genetic information in genes is achieved via complementary base pairing. For example, in transcription, when a cell uses the information in a gene, the DNA sequence is copied into a complementary RNA sequence through the attraction between the DNA and the correct RNA nucleotides. Usually, this RNA copy is then used to make a matching protein sequence in a process called translation, which depends on the same interaction between RNA nucleotides. In an alternative fashion, a cell may copy its genetic information in a process called DNA replication. The details of these functions are covered in other articles; here the focus is on the interactions between DNA and other molecules that mediate the function of the genome.
 Genomic DNA is tightly and orderly packed in the process called DNA condensation, to fit the small available volumes of the cell. In eukaryotes, DNA is located in the cell nucleus, with small amounts in mitochondria and chloroplasts. In prokaryotes, the DNA is held within an irregularly shaped body in the cytoplasm called the nucleoid.[96] The genetic information in a genome is held within genes, and the complete set of this information in an organism is called its genotype. A gene is a unit of heredity and is a region of DNA that influences a particular characteristic in an organism. Genes contain an open reading frame that can be transcribed, and regulatory sequences such as promoters and enhancers, which control transcription of the open reading frame.
 In many species, only a small fraction of the total sequence of the genome encodes protein. For example, only about 1.5% of the human genome consists of protein-coding exons, with over 50% of human DNA consisting of non-coding repetitive sequences.[97] The reasons for the presence of so much noncoding DNA in eukaryotic genomes and the extraordinary differences in genome size, or C-value, among species, represent a long-standing puzzle known as the ""C-value enigma"".[98] However, some DNA sequences that do not code protein may still encode functional non-coding RNA molecules, which are involved in the regulation of gene expression.[99]
 Some noncoding DNA sequences play structural roles in chromosomes. Telomeres and centromeres typically contain few genes but are important for the function and stability of chromosomes.[63][101] An abundant form of noncoding DNA in humans are pseudogenes, which are copies of genes that have been disabled by mutation.[102] These sequences are usually just molecular fossils, although they can occasionally serve as raw genetic material for the creation of new genes through the process of gene duplication and divergence.[103]
 A gene is a sequence of DNA that contains genetic information and can influence the phenotype of an organism. Within a gene, the sequence of bases along a DNA strand defines a messenger RNA sequence, which then defines one or more protein sequences. The relationship between the nucleotide sequences of genes and the amino-acid sequences of proteins is determined by the rules of translation, known collectively as the genetic code. The genetic code consists of three-letter 'words' called codons formed from a sequence of three nucleotides (e.g. ACT, CAG, TTT).
 In transcription, the codons of a gene are copied into messenger RNA by RNA polymerase. This RNA copy is then decoded by a ribosome that reads the RNA sequence by base-pairing the messenger RNA to transfer RNA, which carries amino acids. Since there are 4 bases in 3-letter combinations, there are 64 possible codons (43 combinations). These encode the twenty standard amino acids, giving most amino acids more than one possible codon. There are also three 'stop' or 'nonsense' codons signifying the end of the coding region; these are the TAG, TAA, and TGA codons, (UAG, UAA, and UGA on the mRNA).
 Cell division is essential for an organism to grow, but, when a cell divides, it must replicate the DNA in its genome so that the two daughter cells have the same genetic information as their parent. The double-stranded structure of DNA provides a simple mechanism for DNA replication. Here, the two strands are separated and then each strand's complementary DNA sequence is recreated by an enzyme called DNA polymerase. This enzyme makes the complementary strand by finding the correct base through complementary base pairing and bonding it onto the original strand. As DNA polymerases can only extend a DNA strand in a 5′ to 3′ direction, different mechanisms are used to copy the antiparallel strands of the double helix.[104] In this way, the base on the old strand dictates which base appears on the new strand, and the cell ends up with a perfect copy of its DNA.
 Naked extracellular DNA (eDNA), most of it released by cell death, is nearly ubiquitous in the environment. Its concentration in soil may be as high as 2 μg/L, and its concentration in natural aquatic environments may be as high at 88 μg/L.[105] Various possible functions have been proposed for eDNA: it may be involved in horizontal gene transfer;[106] it may provide nutrients;[107] and it may act as a buffer to recruit or titrate ions or antibiotics.[108] Extracellular DNA acts as a functional extracellular matrix component in the biofilms of several bacterial species. It may act as a recognition factor to regulate the attachment and dispersal of specific cell types in the biofilm;[109] it may contribute to biofilm formation;[110] and it may contribute to the biofilm's physical strength and resistance to biological stress.[111]
 Cell-free fetal DNA is found in the blood of the mother, and can be sequenced to determine a great deal of information about the developing fetus.[112]
 Under the name of environmental DNA eDNA has seen increased use in the natural sciences as a survey tool for ecology, monitoring the movements and presence of species in water, air, or on land, and assessing an area's biodiversity.[113][114]
 Neutrophil extracellular traps (NETs) are networks of extracellular fibers, primarily composed of DNA, which allow neutrophils, a type of white blood cell, to kill extracellular pathogens while minimizing damage to the host cells.
 All the functions of DNA depend on interactions with proteins. These protein interactions can be non-specific, or the protein can bind specifically to a single DNA sequence. Enzymes can also bind to DNA and of these, the polymerases that copy the DNA base sequence in transcription and DNA replication are particularly important.
 Structural proteins that bind DNA are well-understood examples of non-specific DNA-protein interactions. Within chromosomes, DNA is held in complexes with structural proteins. These proteins organize the DNA into a compact structure called chromatin. In eukaryotes, this structure involves DNA binding to a complex of small basic proteins called histones, while in prokaryotes multiple types of proteins are involved.[115][116] The histones form a disk-shaped complex called a nucleosome, which contains two complete turns of double-stranded DNA wrapped around its surface. These non-specific interactions are formed through basic residues in the histones, making ionic bonds to the acidic sugar-phosphate backbone of the DNA, and are thus largely independent of the base sequence.[117] Chemical modifications of these basic amino acid residues include methylation, phosphorylation, and acetylation.[118] These chemical changes alter the strength of the interaction between the DNA and the histones, making the DNA more or less accessible to transcription factors and changing the rate of transcription.[119] Other non-specific DNA-binding proteins in chromatin include the high-mobility group proteins, which bind to bent or distorted DNA.[120] These proteins are important in bending arrays of nucleosomes and arranging them into the larger structures that make up chromosomes.[121]
 A distinct group of DNA-binding proteins is the DNA-binding proteins that specifically bind single-stranded DNA. In humans, replication protein A is the best-understood member of this family and is used in processes where the double helix is separated, including DNA replication, recombination, and DNA repair.[122] These binding proteins seem to stabilize single-stranded DNA and protect it from forming stem-loops or being degraded by nucleases.
 In contrast, other proteins have evolved to bind to particular DNA sequences. The most intensively studied of these are the various transcription factors, which are proteins that regulate transcription. Each transcription factor binds to one particular set of DNA sequences and activates or inhibits the transcription of genes that have these sequences close to their promoters. The transcription factors do this in two ways. Firstly, they can bind the RNA polymerase responsible for transcription, either directly or through other mediator proteins; this locates the polymerase at the promoter and allows it to begin transcription.[124] Alternatively, transcription factors can bind enzymes that modify the histones at the promoter. This changes the accessibility of the DNA template to the polymerase.[125]
 As these DNA targets can occur throughout an organism's genome, changes in the activity of one type of transcription factor can affect thousands of genes.[126] Consequently, these proteins are often the targets of the signal transduction processes that control responses to environmental changes or cellular differentiation and development. The specificity of these transcription factors' interactions with DNA come from the proteins making multiple contacts to the edges of the DNA bases, allowing them to ""read"" the DNA sequence. Most of these base-interactions are made in the major groove, where the bases are most accessible.[24]
 Nucleases are enzymes that cut DNA strands by catalyzing the hydrolysis of the phosphodiester bonds. Nucleases that hydrolyse nucleotides from the ends of DNA strands are called exonucleases, while endonucleases cut within strands. The most frequently used nucleases in molecular biology are the restriction endonucleases, which cut DNA at specific sequences. For instance, the EcoRV enzyme shown to the left recognizes the 6-base sequence 5′-GATATC-3′ and makes a cut at the horizontal line. In nature, these enzymes protect bacteria against phage infection by digesting the phage DNA when it enters the bacterial cell, acting as part of the restriction modification system.[128] In technology, these sequence-specific nucleases are used in molecular cloning and DNA fingerprinting.
 Enzymes called DNA ligases can rejoin cut or broken DNA strands.[129] Ligases are particularly important in lagging strand DNA replication, as they join the short segments of DNA produced at the replication fork into a complete copy of the DNA template. They are also used in DNA repair and genetic recombination.[129]
 Topoisomerases are enzymes with both nuclease and ligase activity. These proteins change the amount of supercoiling in DNA. Some of these enzymes work by cutting the DNA helix and allowing one section to rotate, thereby reducing its level of supercoiling; the enzyme then seals the DNA break.[43] Other types of these enzymes are capable of cutting one DNA helix and then passing a second strand of DNA through this break, before rejoining the helix.[130] Topoisomerases are required for many processes involving DNA, such as DNA replication and transcription.[44]
 Helicases are proteins that are a type of molecular motor. They use the chemical energy in nucleoside triphosphates, predominantly adenosine triphosphate (ATP), to break hydrogen bonds between bases and unwind the DNA double helix into single strands.[131] These enzymes are essential for most processes where enzymes need to access the DNA bases.
 Polymerases are enzymes that synthesize polynucleotide chains from nucleoside triphosphates. The sequence of their products is created based on existing polynucleotide chains—which are called templates. These enzymes function by repeatedly adding a nucleotide to the 3′ hydroxyl group at the end of the growing polynucleotide chain. As a consequence, all polymerases work in a 5′ to 3′ direction.[132] In the active site of these enzymes, the incoming nucleoside triphosphate base-pairs to the template: this allows polymerases to accurately synthesize the complementary strand of their template. Polymerases are classified according to the type of template that they use.
 In DNA replication, DNA-dependent DNA polymerases make copies of DNA polynucleotide chains. To preserve biological information, it is essential that the sequence of bases in each copy are precisely complementary to the sequence of bases in the template strand. Many DNA polymerases have a proofreading activity. Here, the polymerase recognizes the occasional mistakes in the synthesis reaction by the lack of base pairing between the mismatched nucleotides. If a mismatch is detected, a 3′ to 5′ exonuclease activity is activated and the incorrect base removed.[133] In most organisms, DNA polymerases function in a large complex called the replisome that contains multiple accessory subunits, such as the DNA clamp or helicases.[134]
 RNA-dependent DNA polymerases are a specialized class of polymerases that copy the sequence of an RNA strand into DNA. They include reverse transcriptase, which is a viral enzyme involved in the infection of cells by retroviruses, and telomerase, which is required for the replication of telomeres.[62][135] For example, HIV reverse transcriptase is an enzyme for AIDS virus replication.[135] Telomerase is an unusual polymerase because it contains its own RNA template as part of its structure. It synthesizes telomeres at the ends of chromosomes. Telomeres prevent fusion of the ends of neighboring chromosomes and protect chromosome ends from damage.[63]
 Transcription is carried out by a DNA-dependent RNA polymerase that copies the sequence of a DNA strand into RNA. To begin transcribing a gene, the RNA polymerase binds to a sequence of DNA called a promoter and separates the DNA strands. It then copies the gene sequence into a messenger RNA transcript until it reaches a region of DNA called the terminator, where it halts and detaches from the DNA. As with human DNA-dependent DNA polymerases, RNA polymerase II, the enzyme that transcribes most of the genes in the human genome, operates as part of a large protein complex with multiple regulatory and accessory subunits.[136]
 A DNA helix usually does not interact with other segments of DNA, and in human cells, the different chromosomes even occupy separate areas in the nucleus called ""chromosome territories"".[138] This physical separation of different chromosomes is important for the ability of DNA to function as a stable repository for information, as one of the few times chromosomes interact is in chromosomal crossover which occurs during sexual reproduction, when genetic recombination occurs. Chromosomal crossover is when two DNA helices break, swap a section and then rejoin.
 Recombination allows chromosomes to exchange genetic information and produces new combinations of genes, which increases the efficiency of natural selection and can be important in the rapid evolution of new proteins.[139] Genetic recombination can also be involved in DNA repair, particularly in the cell's response to double-strand breaks.[140]
 The most common form of chromosomal crossover is homologous recombination, where the two chromosomes involved share very similar sequences. Non-homologous recombination can be damaging to cells, as it can produce chromosomal translocations and genetic abnormalities. The recombination reaction is catalyzed by enzymes known as recombinases, such as RAD51.[141] The first step in recombination is a double-stranded break caused by either an endonuclease or damage to the DNA.[142] A series of steps catalyzed in part by the recombinase then leads to joining of the two helices by at least one Holliday junction, in which a segment of a single strand in each helix is annealed to the complementary strand in the other helix. The Holliday junction is a tetrahedral junction structure that can be moved along the pair of chromosomes, swapping one strand for another. The recombination reaction is then halted by cleavage of the junction and re-ligation of the released DNA.[143] Only strands of like polarity exchange DNA during recombination. There are two types of cleavage: east-west cleavage and north–south cleavage. The north–south cleavage nicks both strands of DNA, while the east–west cleavage has one strand of DNA intact. The formation of a Holliday junction during recombination makes it possible for genetic diversity, genes to exchange on chromosomes, and expression of wild-type viral genomes.
 DNA contains the genetic information that allows all forms of life to function, grow and reproduce. However, it is unclear how long in the 4-billion-year history of life DNA has performed this function, as it has been proposed that the earliest forms of life may have used RNA as their genetic material.[144][145] RNA may have acted as the central part of early cell metabolism as it can both transmit genetic information and carry out catalysis as part of ribozymes.[146] This ancient RNA world where nucleic acid would have been used for both catalysis and genetics may have influenced the evolution of the current genetic code based on four nucleotide bases. This would occur, since the number of different bases in such an organism is a trade-off between a small number of bases increasing replication accuracy and a large number of bases increasing the catalytic efficiency of ribozymes.[147] However, there is no direct evidence of ancient genetic systems, as recovery of DNA from most fossils is impossible because DNA survives in the environment for less than one million years, and slowly degrades into short fragments in solution.[148] Claims for older DNA have been made, most notably a report of the isolation of a viable bacterium from a salt crystal 250 million years old,[149] but these claims are controversial.[150][151]
 Building blocks of DNA (adenine, guanine, and related organic molecules) may have been formed extraterrestrially in outer space.[152][153][154] Complex DNA and RNA organic compounds of life, including uracil, cytosine, and thymine, have also been formed in the laboratory under conditions mimicking those found in outer space, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe, may have been formed in red giants or in interstellar cosmic dust and gas clouds.[155]
 In February 2021, scientists reported, for the first time, the sequencing of DNA from animal remains, a mammoth in this instance over a million years old, the oldest DNA sequenced to date.[156][157]
 Methods have been developed to purify DNA from organisms, such as phenol-chloroform extraction, and to manipulate it in the laboratory, such as restriction digests and the polymerase chain reaction. Modern biology and biochemistry make intensive use of these techniques in recombinant DNA technology. Recombinant DNA is a man-made DNA sequence that has been assembled from other DNA sequences. They can be transformed into organisms in the form of plasmids or in the appropriate format, by using a viral vector.[158] The genetically modified organisms produced can be used to produce products such as recombinant proteins, used in medical research,[159] or be grown in agriculture.[160][161]
 Forensic scientists can use DNA in blood, semen, skin, saliva or hair found at a crime scene to identify a matching DNA of an individual, such as a perpetrator.[162] This process is formally termed DNA profiling, also called DNA fingerprinting. In DNA profiling, the lengths of variable sections of repetitive DNA, such as short tandem repeats and minisatellites, are compared between people. This method is usually an extremely reliable technique for identifying a matching DNA.[163] However, identification can be complicated if the scene is contaminated with DNA from several people.[164] DNA profiling was developed in 1984 by British geneticist Sir Alec Jeffreys,[165] and first used in forensic science to convict Colin Pitchfork in the 1988 Enderby murders case.[166]
 The development of forensic science and the ability to now obtain genetic matching on minute samples of blood, skin, saliva, or hair has led to re-examining many cases. Evidence can now be uncovered that was scientifically impossible at the time of the original examination. Combined with the removal of the double jeopardy law in some places, this can allow cases to be reopened where prior trials have failed to produce sufficient evidence to convince a jury. People charged with serious crimes may be required to provide a sample of DNA for matching purposes. The most obvious defense to DNA matches obtained forensically is to claim that cross-contamination of evidence has occurred. This has resulted in meticulous strict handling procedures with new cases of serious crime.
 DNA profiling is also used successfully to positively identify victims of mass casualty incidents,[167] bodies or body parts in serious accidents, and individual victims in mass war graves, via matching to family members.
 DNA profiling is also used in DNA paternity testing to determine if someone is the biological parent or grandparent of a child with the probability of parentage is typically 99.99% when the alleged parent is biologically related to the child. Normal DNA sequencing methods happen after birth, but there are new methods to test paternity while a mother is still pregnant.[168]
 Deoxyribozymes, also called DNAzymes or catalytic DNA, were first discovered in 1994.[169] They are mostly single stranded DNA sequences isolated from a large pool of random DNA sequences through a combinatorial approach called in vitro selection or systematic evolution of ligands by exponential enrichment (SELEX). DNAzymes catalyze variety of chemical reactions including RNA-DNA cleavage, RNA-DNA ligation, amino acids phosphorylation-dephosphorylation, carbon-carbon bond formation, etc. DNAzymes can enhance catalytic rate of chemical reactions up to 100,000,000,000-fold over the uncatalyzed reaction.[170] The most extensively studied class of DNAzymes is RNA-cleaving types which have been used to detect different metal ions and designing therapeutic agents. Several metal-specific DNAzymes have been reported including the GR-5 DNAzyme (lead-specific),[169] the CA1-3 DNAzymes (copper-specific),[171] the 39E DNAzyme (uranyl-specific) and the NaA43 DNAzyme (sodium-specific).[172] The NaA43 DNAzyme, which is reported to be more than 10,000-fold selective for sodium over other metal ions, was used to make a real-time sodium sensor in cells.
 Bioinformatics involves the development of techniques to store, data mine, search and manipulate biological data, including DNA nucleic acid sequence data. These have led to widely applied advances in computer science, especially string searching algorithms, machine learning, and database theory.[173] String searching or matching algorithms, which find an occurrence of a sequence of letters inside a larger sequence of letters, were developed to search for specific sequences of nucleotides.[174] The DNA sequence may be aligned with other DNA sequences to identify homologous sequences and locate the specific mutations that make them distinct. These techniques, especially multiple sequence alignment, are used in studying phylogenetic relationships and protein function.[175] Data sets representing entire genomes' worth of DNA sequences, such as those produced by the Human Genome Project, are difficult to use without the annotations that identify the locations of genes and regulatory elements on each chromosome. Regions of DNA sequence that have the characteristic patterns associated with protein- or RNA-coding genes can be identified by gene finding algorithms, which allow researchers to predict the presence of particular gene products and their possible functions in an organism even before they have been isolated experimentally.[176] Entire genomes may also be compared, which can shed light on the evolutionary history of particular organism and permit the examination of complex evolutionary events.
 DNA nanotechnology uses the unique molecular recognition properties of DNA and other nucleic acids to create self-assembling branched DNA complexes with useful properties.[178] DNA is thus used as a structural material rather than as a carrier of biological information. This has led to the creation of two-dimensional periodic lattices (both tile-based and using the DNA origami method) and three-dimensional structures in the shapes of polyhedra.[179] Nanomechanical devices and algorithmic self-assembly have also been demonstrated,[180] and these DNA structures have been used to template the arrangement of other molecules such as gold nanoparticles and streptavidin proteins.[181] DNA and other nucleic acids are the basis of aptamers, synthetic oligonucleotide ligands for specific target molecules used in a range of biotechnology and biomedical applications.[182]
 Because DNA collects mutations over time, which are then inherited, it contains historical information, and, by comparing DNA sequences, geneticists can infer the evolutionary history of organisms, their phylogeny.[183] This field of phylogenetics is a powerful tool in evolutionary biology. If DNA sequences within a species are compared, population geneticists can learn the history of particular populations. This can be used in studies ranging from ecological genetics to anthropology.
 DNA as a storage device for information has enormous potential since it has much higher storage density compared to electronic devices.  However, high costs, slow read and write times (memory latency), and insufficient reliability has prevented its practical use.[184][185]
 
 DNA was first isolated by the Swiss physician Friedrich Miescher who, in 1869, discovered a microscopic substance in the pus of discarded surgical bandages. As it resided in the nuclei of cells, he called it ""nuclein"".[186][187] In 1878, Albrecht Kossel isolated the non-protein component of ""nuclein"", nucleic acid, and later isolated its five primary nucleobases.[188][189]
 In 1909, Phoebus Levene identified the base, sugar, and phosphate nucleotide unit of RNA (then named ""yeast nucleic acid"").[190][191][192] In 1929, Levene identified deoxyribose sugar in ""thymus nucleic acid"" (DNA).[193] Levene suggested that DNA consisted of a string of four nucleotide units linked together through the phosphate groups (""tetranucleotide hypothesis""). Levene thought the chain was short and the bases repeated in a fixed order. In 1927, Nikolai Koltsov proposed that inherited traits would be inherited via a ""giant hereditary molecule"" made up of ""two mirror strands that would replicate in a semi-conservative fashion using each strand as a template"".[194][195] In 1928, Frederick Griffith in his experiment discovered that traits of the ""smooth"" form of Pneumococcus could be transferred to the ""rough"" form of the same bacteria by mixing killed ""smooth"" bacteria with the live ""rough"" form.[196][197] This system provided the first clear suggestion that DNA carries genetic information.
 In 1933, while studying virgin sea urchin eggs, Jean Brachet suggested that DNA is found in the cell nucleus and that RNA is present exclusively in the cytoplasm. At the time, ""yeast nucleic acid"" (RNA) was thought to occur only in plants, while ""thymus nucleic acid"" (DNA) only in animals. The latter was thought to be a tetramer, with the function of buffering cellular pH.[198][199]
 In 1937, William Astbury produced the first X-ray diffraction patterns that showed that DNA had a regular structure.[200]
 In 1943, Oswald Avery, along with co-workers Colin MacLeod and Maclyn McCarty, identified DNA as the transforming principle, supporting Griffith's suggestion (Avery–MacLeod–McCarty experiment).[201] Erwin Chargaff developed and published observations now known as Chargaff's rules, stating that in DNA from any species of any organism, the amount of guanine should be equal to cytosine and the amount of adenine should be equal to thymine.[202][203] Late in 1951, Francis Crick started working with James Watson at the Cavendish Laboratory within the University of Cambridge. DNA's role in heredity was confirmed in 1952 when Alfred Hershey and Martha Chase in the Hershey–Chase experiment showed that DNA is the genetic material of the enterobacteria phage T2.[204]
 In May 1952, Raymond Gosling, a graduate student working under the supervision of Rosalind Franklin, took an X-ray diffraction image, labeled as ""Photo 51"",[205] at high hydration levels of DNA. This photo was given to Watson and Crick by Maurice Wilkins and was critical to their obtaining the correct structure of DNA. Franklin told Crick and Watson that the backbones had to be on the outside. Before then, Linus Pauling, and Watson and Crick, had erroneous models with the chains inside and the bases pointing outwards. Franklin's identification of the space group for DNA crystals revealed to Crick that the two DNA strands were antiparallel.[206] In February 1953, Linus Pauling and Robert Corey proposed a model for nucleic acids containing three intertwined chains, with the phosphates near the axis, and the bases on the outside.[207] Watson and Crick completed their model, which is now accepted as the first correct model of the double helix of DNA. On 28 February 1953 Crick interrupted patrons' lunchtime at The Eagle pub in Cambridge to announce that he and Watson had ""discovered the secret of life"".[208]
 The 25 April 1953 issue of the journal Nature published a series of five articles giving the Watson and Crick double-helix structure DNA and evidence supporting it.[209] The structure was reported in a letter titled ""MOLECULAR STRUCTURE OF NUCLEIC ACIDS A  Structure for Deoxyribose Nucleic Acid"", in which they said, ""It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material.""[9] This letter was followed by a letter from Franklin and Gosling, which was the first publication of their own X-ray diffraction data and of their original analysis method.[47][210] Then followed a letter by Wilkins and two of his colleagues, which contained an analysis of in vivo B-DNA X-ray patterns, and which supported the presence in vivo of the Watson and Crick structure.[48]
 In April 2023, scientists, based on new evidence, concluded that Rosalind Franklin was a contributor and ""equal player"" in the discovery process of DNA, rather than otherwise, as may have been presented subsequently after the time of the discovery.[211][212][213]
 In 1962, after Franklin's death, Watson, Crick, and Wilkins jointly received the Nobel Prize in Physiology or Medicine.[214] Nobel Prizes are awarded only to living recipients. A debate continues about who should receive credit for the discovery.[215]
 In an influential presentation in 1957, Crick laid out the central dogma of molecular biology, which foretold the relationship between DNA, RNA, and proteins, and articulated the ""adaptor hypothesis"".[216] Final confirmation of the replication mechanism that was implied by the double-helical structure followed in 1958 through the Meselson–Stahl experiment.[217] Further work by Crick and co-workers showed that the genetic code was based on non-overlapping triplets of bases, called codons, allowing Har Gobind Khorana, Robert W. Holley, and Marshall Warren Nirenberg to decipher the genetic code.[218] These findings represent the birth of molecular biology.[219]
"
https://en.wikipedia.org/wiki/RNA,RNA,"
 Ribonucleic acid (RNA) is a polymeric molecule essential in various biological roles in coding, decoding, regulation and expression of genes. RNA and deoxyribonucleic acid (DNA) are nucleic acids. Along with lipids, proteins, and carbohydrates, nucleic acids constitute one of the four major macromolecules essential for all known forms of life. Like DNA, RNA is assembled as a chain of nucleotides, but unlike DNA, RNA is found in nature as a single strand folded onto itself, rather than a paired double strand. Cellular organisms use messenger RNA (mRNA) to convey genetic information (using the nitrogenous bases of guanine, uracil, adenine, and cytosine, denoted by the letters G, U, A, and C) that directs synthesis of specific proteins. Many viruses encode their genetic information using an RNA genome.
 Some RNA molecules play an active role within cells by catalyzing biological reactions, controlling gene expression, or sensing and communicating responses to cellular signals. One of these active processes is protein synthesis, a universal function in which RNA molecules direct the synthesis of proteins on ribosomes. This process uses transfer RNA (tRNA) molecules to deliver amino acids to the ribosome, where ribosomal RNA (rRNA) then links amino acids together to form coded proteins.
"
https://en.wikipedia.org/wiki/Cell_division,Cell division,"Cell division is the process by which a parent cell divides into two daughter cells.[1] Cell division usually occurs as part of a larger cell cycle in which the cell grows and replicates its chromosome(s) before dividing.  In eukaryotes, there are two distinct types of cell division: a vegetative division (mitosis), producing daughter cells genetically identical to the parent cell, and a cell division that produces haploid gametes for sexual reproduction (meiosis), reducing the number of chromosomes from two of each type in the diploid parent cell to one of each type in the daughter cells.[2] In cell biology, mitosis (/maɪˈtoʊsɪs/) is a part of the cell cycle, in which, replicated chromosomes are separated into two new nuclei. Cell division gives rise to genetically identical cells in which the total number of chromosomes is maintained. In general, mitosis (division of the nucleus) is preceded by the S stage of interphase (during which the DNA replication occurs) and is often followed by telophase and cytokinesis; which divides the cytoplasm, organelles, and cell membrane of one cell into two new cells containing roughly equal shares of these cellular components. The different stages of mitosis all together define the mitotic (M) phase of animal cell cycle—the division of the mother cell into two genetically identical daughter cells.[3] Meiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions. Homologous chromosomes are separated in the first division, and sister chromatids are separated in the second division. Both of these cell division cycles are used in the process of sexual reproduction at some point in their life cycle. Both are believed to be present in the last eukaryotic common ancestor.
 Prokaryotes (bacteria and archaea) usually undergo a vegetative cell division known as binary fission, where their genetic material is segregated equally into two daughter cells, but there are alternative manners of division, such as budding, that have been observed. All cell divisions, regardless of organism, are preceded by a single round of DNA replication.
 For simple unicellular microorganisms such as the amoeba, one cell division is equivalent to reproduction – an entire new organism is created. On a larger scale, mitotic cell division can create progeny from multicellular organisms, such as plants that grow from cuttings. Mitotic cell division enables sexually reproducing organisms to develop from the one-celled zygote, which itself is produced by fusion of two gametes, each having been produced by meiotic cell division.[4][5] After growth from the zygote to the adult, cell division by mitosis allows for continual construction and repair of the organism.[6] The human body experiences about 10 quadrillion cell divisions in a lifetime.[7]
 The primary concern of cell division is the maintenance of the original cell's genome. Before division can occur, the genomic information that is stored in chromosomes must be replicated, and the duplicated genome must be cleanly divided  between progeny cells.[8] A great deal of cellular infrastructure is involved in ensuring consistency of genomic information among generations.[9][10][11]
"
https://en.wikipedia.org/wiki/Cell_nucleus,Cell nucleus,"
 The cell nucleus (from Latin  nucleus or nuculeus 'kernel, seed'; PL nuclei) is a membrane-bound organelle found in eukaryotic cells. Eukaryotic cells usually have a single nucleus, but a few cell types, such as mammalian red blood cells, have no nuclei, and a few others including osteoclasts have many. The main structures making up the nucleus are the nuclear envelope, a double membrane that encloses the entire organelle and isolates its contents from the cellular cytoplasm; and the nuclear matrix, a network within the nucleus that adds mechanical support.
 The cell nucleus contains nearly all of the cell's genome. Nuclear DNA is often organized into multiple chromosomes – long stands of DNA dotted with various proteins, such as histones, that protect and organize the DNA. The genes within these chromosomes are structured in such a way to promote cell function. The nucleus maintains the integrity of genes and controls the activities of the cell by regulating gene expression.
 Because the nuclear envelope is impermeable to large molecules, nuclear pores are required to regulate nuclear transport of molecules across the envelope. The pores cross both nuclear membranes, providing a channel through which larger molecules must be actively transported by carrier proteins while allowing free movement of small molecules and ions. Movement of large molecules such as proteins and RNA through the pores is required for both gene expression and the maintenance of chromosomes. Although the interior of the nucleus does not contain any membrane-bound subcompartments, a number of nuclear bodies exist, made up of unique proteins, RNA molecules, and particular parts of the chromosomes. The best-known of these is the nucleolus, involved in the assembly of ribosomes.
"
https://en.wikipedia.org/wiki/Multicellular_organism,Multicellular organism,"A multicellular organism is an organism that consists of more than one cell, in contrast to  unicellular organism.[1] All species of animals, land plants and most fungi are multicellular, as are many algae, whereas a few organisms are partially uni- and partially multicellular, like slime molds and social amoebae such as the genus Dictyostelium.[2][3]
 Multicellular organisms arise in various ways, for example by cell division or by aggregation of many single cells.[4][3] Colonial organisms are the result of many identical individuals joining together to form a colony.  However, it can often be hard to separate colonial protists from true multicellular organisms, because the two concepts are not distinct; colonial protists have been dubbed ""pluricellular"" rather than ""multicellular"".[5][6] There are also macroscopic organisms that are multinucleate though technically unicellular, such as the Xenophyophorea that can reach 20 cm.
 Multicellularity has evolved independently at least 25 times in eukaryotes,[7][8] and also in some prokaryotes, like cyanobacteria, myxobacteria, actinomycetes, Magnetoglobus multicellularis or Methanosarcina.[3] However, complex multicellular organisms evolved only in six eukaryotic groups: animals, symbiomycotan fungi, brown algae, red algae, green algae, and land plants.[9] It evolved repeatedly for Chloroplastida (green algae and land plants), once for animals, once for brown algae, three times in the fungi (chytrids, ascomycetes, and basidiomycetes)[10] and perhaps several times for slime molds and red algae.[11] The first evidence of multicellular organization, which is when unicellular organisms coordinate behaviors and may be an evolutionary precursor to true multicellularity, is from cyanobacteria-like organisms that lived 3.0–3.5 billion years ago.[7] To reproduce, true multicellular organisms must solve the problem of regenerating a whole organism from germ cells (i.e., sperm and egg cells), an issue that is studied in evolutionary developmental biology. Animals have evolved a considerable diversity of cell types in a multicellular body (100–150 different cell types), compared with 10–20 in plants and fungi.[12]
 Loss of multicellularity occurred in some groups.[13]  Fungi are predominantly multicellular, though early diverging lineages are largely unicellular (e.g., Microsporidia) and there have been numerous reversions to unicellularity across fungi (e.g., Saccharomycotina, Cryptococcus, and other yeasts).[14][15] It may also have occurred in some red algae (e.g., Porphyridium), but it is possible that they are primitively unicellular.[16] Loss of multicellularity is also considered probable in some green algae (e.g., Chlorella vulgaris and some Ulvophyceae).[17][18] In other groups, generally parasites, a reduction of multicellularity occurred, in number or types of cells (e.g., the myxozoans, multicellular organisms, earlier thought to be unicellular, are probably extremely reduced cnidarians).[19]
 Multicellular organisms, especially long-living animals, face the challenge of cancer, which occurs when cells fail to regulate their growth within the normal program of development. Changes in tissue morphology can be observed during this process. Cancer in animals (metazoans) has often been described as a loss of multicellularity.[20] There is a discussion about the possibility of existence of cancer in other multicellular organisms[21][22] or even in protozoa.[23] For example, plant galls have been characterized as tumors,[24] but some authors argue that plants do not develop cancer.[25]
 In some multicellular groups, which are called Weismannists, a separation between a sterile somatic cell line and a germ cell line evolved. However, Weismannist development is relatively rare (e.g., vertebrates, arthropods, Volvox), as a great part of species have the capacity for somatic embryogenesis (e.g., land plants, most algae, many invertebrates).[26][10]
 One hypothesis for the origin of multicellularity is that a group of function-specific cells aggregated into a slug-like mass called a grex, which moved as a multicellular unit. This is essentially what slime molds do. Another hypothesis is that a primitive cell underwent nucleus division, thereby becoming a coenocyte. A membrane would then form around each nucleus (and the cellular space and organelles occupied in the space), thereby resulting in a group of connected cells in one organism (this mechanism is observable in Drosophila). A third hypothesis is that as a unicellular organism divided, the daughter cells failed to separate, resulting in a conglomeration of identical cells in one organism, which could later develop specialized tissues. This is what plant and animal embryos do as well as colonial choanoflagellates.[27][28]
 Because the first multicellular organisms were simple, soft organisms lacking bone, shell or other hard body parts, they are not well preserved in the fossil record.[29] One exception may be the demosponge, which may have left a chemical signature in ancient rocks. The earliest fossils of multicellular organisms include the contested Grypania spiralis and the fossils of the black shales of the Palaeoproterozoic Francevillian Group Fossil B Formation in Gabon (Gabonionta).[30] The Doushantuo Formation has yielded 600 million year old microfossils with evidence of multicellular traits.[31]
 Until recently, phylogenetic reconstruction has been through anatomical (particularly embryological) similarities. This is inexact, as living multicellular organisms such as animals and plants are more than 500 million years removed from their single-cell ancestors. Such a passage of time allows both divergent and convergent evolution time to mimic similarities and accumulate differences between groups of modern and extinct ancestral species. Modern phylogenetics uses sophisticated techniques such as alloenzymes, satellite DNA and other molecular markers to describe traits that are shared between distantly related lineages.[citation needed]
 The evolution of multicellularity could have occurred in a number of different ways, some of which are described below:
 This theory suggests that the first multicellular organisms occurred from symbiosis (cooperation) of different species of single-cell organisms, each with different roles. Over time these organisms would become so dependent on each other they would not be able to survive independently, eventually leading to the incorporation of their genomes into one multicellular organism.[32] Each respective organism would become a separate lineage of differentiated cells within the newly created species.
 This kind of severely co-dependent symbiosis can be seen frequently, such as in the relationship between clown fish and Riterri sea anemones. In these cases, it is extremely doubtful whether either species would survive very long if the other became extinct. However, the problem with this theory is that it is still not known how each organism's DNA could be incorporated into one single genome to constitute them as a single species. Although such symbiosis is theorized to have occurred (e.g., mitochondria and chloroplasts in animal and plant cells—endosymbiosis), it has happened only extremely rarely and, even then, the genomes of the endosymbionts have retained an element of distinction, separately replicating their DNA during mitosis of the host species. For instance, the two or three symbiotic organisms forming the composite lichen, although dependent on each other for survival, have to separately reproduce and then re-form to create one individual organism once more.[citation needed]
 This theory states that a single unicellular organism, with multiple nuclei, could have developed internal membrane partitions around each of its nuclei.[33] Many protists such as the ciliates or slime molds can have several nuclei, lending support to this hypothesis. However, the simple presence of multiple nuclei is not enough to support the theory. Multiple nuclei of ciliates are dissimilar and have clear differentiated functions. The macronucleus serves the organism's needs, whereas the micronucleus is used for sexual reproduction with exchange of genetic material. Slime molds syncitia form from individual amoeboid cells, like syncitial tissues of some multicellular organisms, not the other way round. To be deemed valid, this theory needs a demonstrable example and mechanism of generation of a multicellular organism from a pre-existing syncytium.[citation needed]
 The colonial theory of Haeckel, 1874, proposes that the symbiosis of many organisms of the same species (unlike the symbiotic theory, which suggests the symbiosis of different species) led to a multicellular organism. At least some, it is presumed land-evolved, multicellularity occurs by cells separating and then rejoining (e.g., cellular slime molds) whereas for the majority of multicellular types (those that evolved within aquatic environments), multicellularity occurs as a consequence of cells failing to separate following division.[34] The mechanism of this latter colony formation can be as simple as incomplete cytokinesis, though multicellularity is also typically considered to involve cellular differentiation.[35]
 The advantage of the Colonial Theory hypothesis is that it has been seen to occur independently in 16 different protoctistan phyla. For instance, during food shortages the amoeba Dictyostelium groups together in a colony that moves as one to a new location. Some of these amoeba then slightly differentiate from each other. Other examples of colonial organisation in protista are Volvocaceae, such as Eudorina and Volvox, the latter of which consists of up to 500–50,000 cells (depending on the species), only a fraction of which reproduce.[36] For example, in one species 25–35 cells reproduce, 8 asexually and around 15–25 sexually. However, it can often be hard to separate colonial protists from true multicellular organisms, as the two concepts are not distinct; colonial protists have been dubbed ""pluricellular"" rather than ""multicellular"".[5]
 Some authors suggest that the origin of multicellularity, at least in Metazoa, occurred due to a transition from temporal to spatial cell differentiation, rather than through a gradual evolution of cell differentiation, as affirmed in Haeckel's gastraea theory.[37]
 About 800 million years ago,[38] a minor genetic change in a single molecule called guanylate kinase protein-interaction domain (GK-PID) may have allowed organisms to go from a single cell organism to one of many cells.[39]
 Genes borrowed from viruses and mobile genetic elements (MGEs) have recently been identified as playing a crucial role in the differentiation of multicellular tissues and organs and even in sexual reproduction, in the fusion of egg cell and sperm.[40][41]
Such fused cells are also involved in metazoan membranes such as those that prevent chemicals crossing the placenta and the brain body separation.[40] Two viral components have been identified. The first is syncytin, which came from a virus.[42]
The second identified in 2007 is called EFF1, which helps form the skin of Caenorhabditis elegans, part of a whole family of FF proteins. Felix Rey, of the Pasteur Institute in Paris has constructed the 3D structure of the EFF1 protein[43] and shown it does the work of linking one cell to another, in viral infections.
The fact that all known cell fusion molecules are viral in origin suggests that they have been vitally important to the inter-cellular communication systems that enabled multicellularity.  Without the ability of cellular fusion, colonies could have formed, but anything even as complex as a sponge would not have been possible.[44]
 This theory suggests that the oxygen available in the atmosphere of early Earth could have been the limiting factor for the emergence of multicellular life.[45] This hypothesis is based on the correlation between the emergence of multicellular life and the increase of oxygen levels during this time. This would have taken place after the Great Oxidation Event but before the most recent rise in oxygen. Mills[46] concludes that the amount of oxygen present during the Ediacaran is not necessary for complex life and therefore is unlikely to have been the driving factor for the origin of multicellularity.
 A snowball Earth is a geological event where the entire surface of the Earth is covered in snow and ice. The term can either refer to individual events (of which there were at least two) or to the larger geologic period during which all the known total glaciations occurred.
 The most recent snowball Earth took place during the Cryogenian period and consisted of two global glaciation events known as the Sturtian and Marinoan glaciations. Xiao et al.[47] suggest that between the period of time known as the ""Boring Billion"" and the snowball Earth, simple life could have had time to innovate and evolve, which could later lead to the evolution of multicellularity.
 The snowball Earth hypothesis in regards to multicellularity proposes that the Cryogenian period in Earth history could have been the catalyst for the evolution of complex multicellular life. Brocks[48] suggests that the time between the Sturtian Glacian and the more recent Marinoan Glacian allowed for planktonic algae to dominate the seas making way for rapid diversity of life for both plant and animal lineages. Complex life quickly emerged and diversified in what is known as the Cambrian explosion shortly after the Marinoan.[citation needed]
 The predation hypothesis suggests that in order to avoid being eaten by predators, simple single-celled organisms evolved multicellularity to make it harder to be consumed as prey. Herron et al.[49] performed laboratory evolution experiments on the single-celled green alga, Chlamydomonas reinhardtii, using paramecium as a predator. They found that in the presence of this predator, C. reinhardtii does indeed evolve simple multicellular features.
 Multicellularity allows an organism to exceed the size limits normally imposed by diffusion: single cells with increased size have a decreased surface-to-volume ratio and have difficulty absorbing sufficient nutrients and transporting them throughout the cell. Multicellular organisms thus have the competitive advantages of an increase in size without its limitations.  They can have longer lifespans as they can continue living when individual cells die. Multicellularity also permits increasing complexity by allowing differentiation of cell types within one organism.
 Whether all of these can be seen as advantages however is debatable: The vast majority of living organisms are single celled, and even in terms of biomass, single celled organisms are far more successful than animals, although not plants.[50]
Rather than seeing traits such as longer lifespans and greater size as an advantage, many biologists see these only as examples of diversity, with associated tradeoffs.
"
https://en.wikipedia.org/wiki/Evolution_of_sexual_reproduction,Evolution of sexual reproduction,"
 Sexual reproduction is an adaptive feature which is common to almost all multicellular organisms and various unicellular organisms, with some organisms being incapable of asexual reproduction.  Currently the adaptive advantage of sexual reproduction is widely regarded as a major unsolved problem in biology.  As discussed below, one prominent theory is that sex evolved as an efficient mechanism for producing variation, and this had the advantage of enabling organisms to adapt to changing environments.  Another prominent theory, also discussed below, is that a primary advantage of outcrossing sex is the masking of the expression of deleterious mutations.[1]  Additional theories concerning the adaptive advantage of sex are also discussed below.  Sex does, however, come with a cost. In reproducing asexually, no time nor energy needs to be expended in choosing a mate. And if the environment has not changed, then there may be little reason for variation, as the organism may already be well-adapted. Sex also halves the amount of offspring a given population is able to produce. Sex, however, has evolved as the most prolific means of species branching into the tree of life. Diversification into the phylogenetic tree happens much more rapidly via sexual reproduction than it does by way of asexual reproduction.
 Evolution of sexual reproduction describes how sexually reproducing animals, plants, fungi and protists could have evolved from a common ancestor that was a single-celled eukaryotic species.[2][3][4] Sexual reproduction is widespread in the Eukarya, though a few eukaryotic species have secondarily lost the ability to reproduce sexually, such as Bdelloidea, and some plants and animals routinely reproduce asexually (by apomixis and parthenogenesis) without entirely having lost sex. The evolution of sex contains two related yet distinct themes: its origin and its maintenance.
 Although Bacteria and Archaea (prokaryotes) have processes that can transfer DNA from one cell to another (conjugation, transformation, and transduction[5]), these processes are not evolutionarily related to sexual reproduction in Eukaryotes.[6] In eukaryotes, true sexual reproduction by meiosis and cell fusion is thought to have arisen in the last eukaryotic common ancestor, possibly via several processes of varying success, and then to have persisted.[7]
 Since hypotheses for the origin of sex are difficult to verify experimentally (outside of evolutionary computation), most current work has focused on the persistence of sexual reproduction over evolutionary time. The maintenance of sexual reproduction (specifically, of its dioecious form) by natural selection in a highly competitive world has long been one of the major mysteries of biology, since both other known mechanisms of reproduction – asexual reproduction and hermaphroditism – possess apparent advantages over it. Asexual reproduction can proceed by budding, fission, or spore formation and does not involve the union of gametes, which accordingly results in a much faster rate of reproduction compared to sexual reproduction, where 50% of offspring are males and unable to produce offspring themselves. In hermaphroditic reproduction, each of the two parent organisms required for the formation of a zygote can provide either the male or the female gamete, which leads to advantages in both size and genetic variance of a population.
 Sexual reproduction therefore must offer significant fitness advantages because, despite the two-fold cost of sex (see below), it dominates among multicellular forms of life, implying that the fitness of offspring produced by sexual processes outweighs the costs. Sexual reproduction derives from recombination, where parent genotypes are reorganized and shared with the offspring. This stands in contrast to single-parent asexual replication, where the offspring is always identical to the parents (barring mutation). Recombination supplies two fault-tolerance mechanisms at the molecular level: recombinational DNA repair (promoted during meiosis because homologous chromosomes pair at that time) and complementation (also known as heterosis, hybrid vigor or masking of mutations).
 Reproduction, including modes of sexual reproduction, features in the writings of Aristotle; modern philosophical-scientific thinking on the problem dates from at least Erasmus Darwin (1731–1802) in the 18th century.[8] August Weismann picked up the thread in 1885, arguing that sex serves to generate genetic variation, as detailed in the majority of the explanations below.[9] On the other hand, Charles Darwin (1809–1882) concluded that the effect of hybrid vigor (complementation) ""is amply sufficient to account for the … genesis of the two sexes"".[10] This is consistent with the repair and complementation hypothesis, described below. Since the emergence of the modern evolutionary synthesis in the 20th century, numerous biologists including W. D. Hamilton, Alexey Kondrashov, George C. Williams, Harris Bernstein, Carol Bernstein, Michael M. Cox, Frederic A. Hopf and Richard E. Michod – have suggested competing explanations for how a vast array of different living species maintain sexual reproduction.
 The concept of sex includes two fundamental phenomena: the sexual process (fusion of genetic information of two individuals) and sexual differentiation (separation of this information into two parts). Depending on the presence or absence of these phenomena, all of the existing forms of reproduction can be classified as asexual, hermaphrodite or dioecious. The sexual process and sexual differentiation are different phenomena, and, in essence, are diametrically opposed. The first creates (increases) diversity of genotypes, and the second decreases it by half.
 Reproductive advantages of the asexual forms are in quantity of the progeny, and the advantages of the hermaphrodite forms are in maximal diversity. Transition from the hermaphrodite to dioecious state leads to a loss of at least half of the diversity. So, the primary challenge is to explain the advantages given by sexual differentiation, i.e. the benefits of two separate sexes compared to hermaphrodites rather than to explain benefits of sexual forms (hermaphrodite + dioecious) over asexual ones. It has already been understood that since sexual reproduction is not associated with any clear reproductive advantages, as compared with asexual, there should be some important advantages in evolution.[11][better source needed]
 For the advantage due to genetic variation, there are three possible reasons this might happen. First, sexual reproduction can combine the effects of two beneficial mutations in the same individual (i.e. sex aids in the spread of advantageous traits). Also, the necessary mutations do not have to have occurred one after another in a single line of descendants.[12][unreliable source?] Second, sex acts to bring together currently deleterious mutations to create severely unfit individuals that are then eliminated from the population (i.e. sex aids in the removal of deleterious genes). However, in organisms containing only one set of chromosomes, deleterious mutations would be eliminated immediately, and therefore removal of harmful mutations is an unlikely benefit for sexual reproduction. Lastly, sex creates new gene combinations that may be more fit than previously existing ones, or may simply lead to reduced competition among relatives.
 For the advantage due to DNA repair, there is an immediate large benefit of removing DNA damage by recombinational DNA repair during meiosis, since this removal allows greater survival of progeny with undamaged DNA. The advantage of complementation to each sexual partner is avoidance of the bad effects of their deleterious recessive genes in progeny by the masking effect of normal dominant genes contributed by the other partner.[citation needed]
 The classes of hypotheses based on the creation of variation are further broken down below. Any number of these hypotheses may be true in any given species (they are not mutually exclusive), and different hypotheses may apply in different species. However, a research framework based on creation of variation has yet to be found that allows one to determine whether the reason for sex is universal for all sexual species, and, if not, which mechanisms are acting in each species.
 On the other hand, the maintenance of sex based on DNA repair and complementation applies widely to all sexual species.
 In contrast to the view that sex promotes genetic variation, Heng,[13] and Gorelick and Heng[14] reviewed evidence that sex actually acts as a constraint on genetic variation. They consider that sex acts as a coarse filter, weeding out major genetic changes, such as chromosomal rearrangements, but permitting minor variation, such as changes at the nucleotide or gene level (that are often neutral) to pass through the sexual sieve.
 Sex could be a method by which novel genotypes are created. Because sex combines genes from two individuals, sexually reproducing populations can more easily combine advantageous genes than can asexual populations. If, in a sexual population, two different advantageous alleles arise at different loci on a chromosome in different members of the population, a chromosome containing the two advantageous alleles can be produced within a few generations by recombination. However, should the same two alleles arise in different members of an asexual population, the only way that one chromosome can develop the other allele is to independently gain the same mutation, which would take much longer. Several studies have addressed counterarguments, and the question of whether this model is sufficiently robust to explain the predominance of sexual versus asexual reproduction remains.[15]: 73–86 
 Ronald Fisher suggested that sex might facilitate the spread of advantageous genes by allowing them to better escape their genetic surroundings, if they should arise on a chromosome with deleterious genes.
 Supporters of these theories respond to the balance argument that the individuals produced by sexual and asexual reproduction may differ in other respects too – which may influence the persistence of sexuality. For example, in the heterogamous water fleas of the genus Cladocera, sexual offspring form eggs which are better able to survive the winter versus those the fleas produce asexually.
 One of the most widely discussed theories to explain the persistence of sex is that it is maintained to assist sexual individuals in resisting parasites, also known as the Red Queen Hypothesis.[16][15]: 113–117 [17][18][19]
 When an environment changes, previously neutral or deleterious alleles can become favourable. If the environment changed sufficiently rapidly (i.e. between generations), these changes in the environment can make sex advantageous for the individual. Such rapid changes in environment are caused by the co-evolution between hosts and parasites.
 Imagine, for example that there is one gene in parasites with two alleles p and P conferring two types of parasitic ability, and one gene in hosts with two alleles h and H, conferring two types of parasite resistance, such that parasites with allele p can attach themselves to hosts with the allele h, and P to H. Such a situation will lead to cyclic changes in allele frequency – as p increases in frequency, h will be disfavoured.
 In reality, there will be several genes involved in the relationship between hosts and parasites. In an asexual population of hosts, offspring will only have the different parasitic resistance if a mutation arises. In a sexual population of hosts, however, offspring will have a new combination of parasitic resistance alleles.
 In other words, like Lewis Carroll's Red Queen, sexual hosts are continually ""running"" (adapting) to ""stay in one place"" (resist parasites).
 Evidence for this explanation for the evolution of sex is provided by comparison of the rate of molecular evolution of genes for kinases and immunoglobulins in the immune system with genes coding other proteins. The genes coding for immune system proteins evolve considerably faster.[20][21]
 Further evidence for the Red Queen hypothesis was provided by observing long-term dynamics and parasite coevolution in a ""mixed"" (sexual and asexual) population of snails (Potamopyrgus antipodarum). The number of sexuals, the number asexuals, and the rates of parasite infection for both were monitored. It was found that clones that were plentiful at the beginning of the study became more susceptible to parasites over time. As parasite infections increased, the once plentiful clones dwindled dramatically in number. Some clonal types disappeared entirely. Meanwhile, sexual snail populations remained much more stable over time.[22][23]
 However, Hanley et al.[24] studied mite infestations of a parthenogenetic gecko species and its two related sexual ancestral species. Contrary to expectation based on the Red Queen hypothesis, they found that the prevalence, abundance and mean intensity of mites in sexual geckos was significantly higher than in asexuals sharing the same habitat.
 In 2011, researchers used the microscopic roundworm Caenorhabditis elegans as a host and the pathogenic bacteria Serratia marcescens to generate a host-parasite coevolutionary system in a controlled environment, allowing them to conduct more than 70 evolution experiments testing the Red Queen Hypothesis. They genetically manipulated the mating system of C. elegans, causing populations to mate either sexually, by self-fertilization, or a mixture of both within the same population. Then they exposed those populations to the S. marcescens parasite. It was found that the self-fertilizing populations of C. elegans were rapidly driven extinct by the coevolving parasites while sex allowed populations to keep pace with their parasites, a result consistent with the Red Queen Hypothesis.[25][26] In natural populations of C. elegans, self-fertilization is the predominant mode of reproduction, but infrequent out-crossing events occur at a rate of about 1%.[27]
 Critics of the Red Queen hypothesis question whether the constantly changing environment of hosts and parasites is sufficiently common to explain the evolution of sex. In particular, Otto and Nuismer [28] presented results showing that species interactions (e.g. host vs parasite interactions) typically select against sex. They concluded that, although the Red Queen hypothesis favors sex under certain circumstances, it alone does not account for the ubiquity of sex. Otto and Gerstein [29] further stated that ""it seems doubtful to us that strong selection per gene is sufficiently commonplace for the Red Queen hypothesis to explain the ubiquity of sex"". Parker[30] reviewed numerous genetic studies on plant disease resistance and failed to uncover a single example consistent with the assumptions of the Red Queen hypothesis.
 The paradox of the existence of sexual reproduction is that though it is ubiquitous in multicellular organisms, there are ostensibly many inherent disadvantages to reproducing sexually when weighed against the relative advantages of alternative forms of reproduction, such as asexual reproduction. Thus, because sexual reproduction abounds in complex multicellular life, there must be some significant benefit(s) to sex and sexual reproduction that compensates for these fundamental disadvantages.
 Among the most limiting disadvantages to the evolution of sexual reproduction by natural selection is that an asexual population can grow much more rapidly than a sexual one with each generation.
 For example, assume that the entire population of some theoretical species has 100 total organisms consisting of two sexes (i.e. males and females), with 50:50 male-to-female representation, and that only the females of this species can bear offspring. If all capable members of this population procreated once, a total of 50 offspring would be produced (the F1 generation). Contrast this outcome with an asexual species, in which each and every member of an equally sized 100-organism population is capable of bearing young. If all capable members of this asexual population procreated once, a total of 100 offspring would be produced – twice as many as produced by the sexual population in a single generation.
 This idea is sometimes referred to as the two-fold cost of sexual reproduction. It was first described mathematically by John Maynard Smith.[31][page needed] In his manuscript, Smith further speculated on the impact of an asexual mutant arising in a sexual population, which suppresses meiosis and allows eggs to develop into offspring genetically identical to the mother by mitotic division.[32][page needed] The mutant-asexual lineage would double its representation in the population each generation, all else being equal.
 Technically the problem above is not one of sexual reproduction but of having a subset of organisms incapable of bearing offspring. Indeed, some multicellular organisms (isogamous) engage in sexual reproduction but all members of the species are capable of bearing offspring.[33][page needed] The two-fold reproductive disadvantage assumes that males contribute only genes to their offspring and sexual females waste half their reproductive potential on sons.[32][page needed] Thus, in this formulation, the principal cost of sex is that males and females must successfully copulate, which almost always involves expending energy to come together through time and space. Asexual organisms need not expend the energy necessary to find a mate.
 Sexual reproduction implies that chromosomes and alleles segregate and recombine in every generation, but not all genes are transmitted together to the offspring.[32][page needed] There is a chance of spreading mutants that cause unfair transmission at the expense of their non-mutant colleagues. These mutations are referred to as ""selfish"" because they promote their own spread at the cost of alternative alleles or of the host organism; they include nuclear meiotic drivers and selfish cytoplasmic genes.[32][page needed] Meiotic drivers are genes that distort meiosis to produce gametes containing themselves more than the 50% of the time expected by chance. A selfish cytoplasmic gene is a gene located in an organelle, plasmid or intracellular parasite that modifies reproduction to cause its own increase at the expense of the cell or organism that carries it.[32][page needed]
 A sexually reproducing organism only passes on ~50% of its own genetic material to each L2 offspring. This is a consequence of the fact that gametes from sexually reproducing species are haploid. Again, however, this is not applicable to all sexual organisms. There are numerous species which are sexual but do not have a genetic-loss problem because they do not produce males or females. Yeast, for example, are isogamous sexual organisms which have two mating types which fuse and recombine their haploid genomes. Both sexes reproduce during the haploid and diploid stages of their life cycle and have a 100% chance of passing their genes into their offspring.[33][page needed]
 Some species avoid the 50% cost of sexual reproduction, although they have ""sex"" (in the sense of genetic recombination). In these species (e.g., bacteria, ciliates, dinoflagellates and diatoms), ""sex"" and reproduction occurs separately.[34][35]
 As discussed in the earlier part of this article, sexual reproduction is conventionally explained as an adaptation for producing genetic variation through allelic recombination. As acknowledged above, however, serious problems with this explanation have led many biologists to conclude that the benefit of sex is a major unsolved problem in evolutionary biology.
 An alternative ""informational"" approach to this problem has led to the view that the two fundamental aspects of sex, genetic recombination and outcrossing, are adaptive responses to the two major sources of ""noise"" in transmitting genetic information. Genetic noise can occur as either physical damage to the genome (e.g. chemically altered bases of DNA or breaks in the chromosome) or replication errors (mutations).[36][37][38] This alternative view is referred to as the repair and complementation hypothesis, to distinguish it from the traditional variation hypothesis.
 The repair and complementation hypothesis assumes that genetic recombination is fundamentally a DNA repair process, and that when it occurs during meiosis it is an adaptation for repairing the genomic DNA which is passed on to progeny. Recombinational repair is the only repair process known which can accurately remove double-strand damages in DNA, and such damages are both common in nature and ordinarily lethal if not repaired. For instance, double-strand breaks in DNA occur about 50 times per cell cycle in human cells (see naturally occurring DNA damage). Recombinational repair is prevalent from the simplest viruses to the most complex multicellular eukaryotes. It is effective against many different types of genomic damage, and in particular is highly efficient at overcoming double-strand damages. Studies of the mechanism of meiotic recombination indicate that meiosis is an adaptation for repairing DNA.[39]  These considerations form the basis for the first part of the repair and complementation hypothesis.
 In some lines of descent from the earliest organisms, the diploid stage of the sexual cycle, which was at first transient, became the predominant stage, because it allowed complementation — the masking of deleterious recessive mutations (i.e. hybrid vigor or heterosis). Outcrossing, the second fundamental aspect of sex, is maintained by the advantage of masking mutations and the disadvantage of inbreeding (mating with a close relative) which allows expression of recessive mutations (commonly observed as inbreeding depression). This is in accord with Charles Darwin,[40] who concluded that the adaptive advantage of sex is hybrid vigor; or as he put it, ""the offspring of two individuals, especially if their progenitors have been subjected to very different conditions, have a great advantage in height, weight, constitutional vigor and fertility over the self fertilised offspring from either one of the same parents.""
 However, outcrossing may be abandoned in favor of parthenogenesis or selfing (which retain the advantage of meiotic recombinational repair) under conditions in which the costs of mating are very high. For instance, costs of mating are high when individuals are rare in a geographic area, such as when there has been a forest fire and the individuals entering the burned area are the initial ones to arrive. At such times mates are hard to find, and this favors parthenogenic species.
 In the view of the repair and complementation hypothesis, the removal of DNA damage by recombinational repair produces a new, less deleterious form of informational noise, allelic recombination, as a by-product. This lesser informational noise generates genetic variation, viewed by some as the major effect of sex, as discussed in the earlier parts of this article.
 Mutations can have many different effects upon an organism. It is generally believed that the majority of non-neutral mutations are deleterious, which means that they will cause a decrease in the organism's overall fitness.[41][page range too broad] If a mutation has a deleterious effect, it will then usually be removed from the population by the process of natural selection. Sexual reproduction is believed to be more efficient than asexual reproduction in removing those mutations from the genome.[42]
 There are two main hypotheses which explain how sex may act to remove deleterious genes from the genome.
 While DNA is able to recombine to modify alleles, DNA is also susceptible to mutations within the sequence that can affect an organism in a negative manner. Asexual organisms do not have the ability to recombine their genetic information to form new and differing alleles. Once a mutation occurs in the DNA or other genetic carrying sequence, there is no way for the mutation to be removed from the population until another mutation occurs that ultimately deletes the primary mutation. This is rare among organisms.
 Hermann Joseph Muller introduced the idea that mutations build up in asexual reproducing organisms. Muller described this occurrence by comparing the mutations that accumulate as a ratchet. Each mutation that arises in asexually reproducing organisms turns the ratchet once. The ratchet is unable to be rotated backwards, only forwards. The next mutation that occurs turns the ratchet once more. Additional mutations in a population continually turn the ratchet and the mutations, mostly deleterious, continually accumulate without recombination.[43] These mutations are passed onto the next generation because the offspring are exact genetic clones of their parents. The genetic load of organisms and their populations will increase due to the addition of multiple deleterious mutations and decrease the overall reproductive success and fitness.
 For sexually reproducing populations, studies have shown that single-celled bottlenecks are beneficial for resisting mutation build-up[citation needed]. Passaging a population through a single-celled bottleneck involves the fertilization event occurring with haploid sets of DNA, forming one fertilized cell. For example, humans undergo a single-celled bottleneck in that the haploid sperm fertilizes the haploid egg, forming the diploid zygote, which is unicellular. This passage through a single cell is beneficial in that it lowers the chance of mutations from being passed on through multiple individuals. Instead, the mutation is only passed onto one individual.[44] Further studies using Dictyostelium discoideum suggest that this unicellular initial stage is important for resisting mutations due to the importance of high relatedness. Highly related individuals are more closely related, and more clonal, whereas less related individuals are less so, increasing the likelihood that an individual in a population of low relatedness may have a detrimental mutation. Highly related populations also tend to thrive better than lowly related because the cost of sacrificing an individual is greatly offset by the benefit gained by its relatives and in turn, its genes, according to kin selection. The studies with D. discoideum showed that conditions of high relatedness resisted mutant individuals more effectively than those of low relatedness, suggesting the importance of high relatedness to resist mutations from proliferating.[45]
 This hypothesis was proposed by Alexey Kondrashov, and is sometimes known as the deterministic mutation hypothesis.[42] It assumes that the majority of deleterious mutations are only slightly deleterious, and affect the individual such that the introduction of each additional mutation has an increasingly large effect on the fitness of the organism. This relationship between number of mutations and fitness is known as synergistic epistasis.
 By way of analogy, think of a car with several minor faults. Each is not sufficient alone to prevent the car from running, but in combination, the faults combine to prevent the car from functioning.
 Similarly, an organism may be able to cope with a few defects, but the presence of many mutations could overwhelm its backup mechanisms.
 Kondrashov argues that the slightly deleterious nature of mutations means that the population will tend to be composed of individuals with a small number of mutations. Sex will act to recombine these genotypes, creating some individuals with fewer deleterious mutations, and some with more. Because there is a major selective disadvantage to individuals with more mutations, these individuals die out. In essence, sex compartmentalises the deleterious mutations.
 There has been much criticism of Kondrashov's theory, since it relies on two key restrictive conditions. The first requires that the rate of deleterious mutation should exceed one per genome per generation in order to provide a substantial advantage for sex. While there is some empirical evidence for it (for example in Drosophila[48] and E. coli[49]), there is also strong evidence against it. Thus, for instance, for the sexual species Saccharomyces cerevisiae (yeast) and Neurospora crassa (fungus), the mutation rate per genome per replication are 0.0027 and 0.0030 respectively. For the nematode worm Caenorhabditis elegans, the mutation rate per effective genome per sexual generation is 0.036.[50] Secondly, there should be strong interactions among loci (synergistic epistasis), a mutation-fitness relation for which there is only limited evidence.[51] Conversely, there is also the same amount of evidence that mutations show no epistasis (purely additive model) or antagonistic interactions (each additional mutation has a disproportionally small effect).
 Geodakyan suggested that sexual dimorphism provides a partitioning of a species' phenotypes into at least two functional partitions: a female partition that secures beneficial features of the species and a male partition that emerged in species with more variable and unpredictable environments. The male partition is suggested to be an ""experimental"" part of the species that allows the species to expand their ecological niche, and to have alternative configurations. This theory underlines the higher variability and higher mortality in males, in comparison to females. This functional partitioning also explains the higher susceptibility to disease in males, in comparison to females and therefore includes the idea of ""protection against parasites"" as another functionality of male sex. Geodakyan's evolutionary theory of sex was developed in Russia in 1960–1980 and was not known to the West till the era of the Internet. Trofimova, who analysed psychological sex differences, hypothesised that the male sex might also provide a ""redundancy pruning"" function.[52]
 Ilan Eshel suggested that sex prevents rapid evolution. He suggests that recombination breaks up favourable gene combinations more often than it creates them, and sex is maintained because it ensures selection is longer-term than in asexual populations – so the population is less affected by short-term changes.[15]: 85–86 [53] This explanation is not widely accepted, as its assumptions are very restrictive.
 It has recently been shown in experiments with Chlamydomonas algae that sex can remove the speed limit[clarification needed] on evolution.[54]
 An information theoretic analysis using a simplified but useful model shows that in asexual reproduction, the information gain per generation of a species is limited to 1 bit per generation, while in sexual reproduction, the information gain is bounded by 





G




{\displaystyle {\sqrt {G}}}

, where 



G


{\displaystyle G}

 is the size of the genome in bits.[55]
 The evolution of sex can alternatively be described as a kind of gene exchange that is independent from reproduction.[56] According to the Thierry Lodé's ""libertine bubble theory"", sex originated from an archaic gene transfer process among prebiotic bubbles.[57][58] The contact among the pre-biotic bubbles could, through simple food or parasitic reactions, promote the transfer of genetic material from one bubble to another. That interactions between two organisms be in balance appear to be a sufficient condition to make these interactions evolutionarily efficient, i.e. to select bubbles that tolerate these interactions (""libertine"" bubbles) through a blind evolutionary process of self-reinforcing gene correlations and compatibility.[59]
 The ""libertine bubble theory"" proposes that meiotic sex evolved in proto-eukaryotes to solve a problem that bacteria did not have, namely a large amount of DNA material, occurring in an archaic step of proto-cell formation and genetic exchanges. So that, rather than providing selective advantages through reproduction, sex could be thought of as a series of separate events which combines step-by-step some very weak benefits of recombination, meiosis, gametogenesis and syngamy.[60] Therefore, current sexual species could be descendants of primitive organisms that practiced more stable exchanges in the long term, while asexual species have emerged, much more recently in evolutionary history, from the conflict of interest resulting from anisogamy.[clarification needed]
 Parasites and Muller's ratchet
 R. Stephen Howard and Curtis Lively were the first to suggest that the combined effects of parasitism and mutation accumulation can lead to an increased advantage to sex under conditions not otherwise predicted (Nature, 1994).  Using computer simulations, they showed that when the two mechanisms act simultaneously the advantage to sex over asexual reproduction is larger than for either factor operating alone.
 Many protists reproduce sexually, as do many multicellular plants, animals, and fungi. In the eukaryotic fossil record, sexual reproduction first appeared about 2.0 billion years ago in the Proterozoic Eon,[61][62] although a later date, 1.2 billion years ago, has also been presented.[63][64] Nonetheless, all sexually reproducing eukaryotic organisms likely derive from a single-celled common ancestor.[2][65][57] It is probable that the evolution of sex was an integral part of the evolution of the first eukaryotic cell.[66][67]  There are a few species which have secondarily lost this feature, such as Bdelloidea and some parthenocarpic plants.
 Organisms need to replicate their genetic material in an efficient and reliable manner. The necessity to repair genetic damage is one of the leading theories explaining the origin of sexual reproduction. Diploid individuals can repair a damaged section of their DNA via homologous recombination, since there are two copies of the gene in the cell and if one copy is damaged, the other copy is unlikely to be damaged at the same site.
 A harmful damage in a haploid individual, on the other hand, is more likely to become fixed (i.e. permanent), since any DNA repair mechanism would have no source from which to recover the original undamaged sequence.[36] The most primitive form of sex may have been one organism with damaged DNA replicating an undamaged strand from a similar organism in order to repair itself.[68]
 Sexual reproduction appears to have arisen very early in eukaryotic evolution, implying that the essential features of meiosis were already present in the last eukaryotic common ancestor.[69][65][70] In extant organisms, proteins with central functions in meiosis are similar to key proteins in natural transformation in bacteria and DNA transfer in archaea.[70][71] For example, recA recombinase, that catalyses the key functions of DNA homology search and strand exchange in the bacterial sexual process of transformation, has orthologs in eukaryotes that perform similar functions in meiotic recombination[70]
 Natural transformation in bacteria, DNA transfer in archaea, and meiosis in eukaryotic microorganisms are induced by stressful circumstances such as overcrowding, resource depletion, and DNA damaging conditions.[59][70][71] This suggests that these sexual processes are adaptations for dealing with stress, particularly stress that causes DNA damage. In bacteria, these stresses induce an altered physiologic state, termed competence, that allows active take-up of DNA from a donor bacterium and the integration of this DNA into the recipient genome (see Natural competence) allowing recombinational repair of the recipients' damaged DNA.[72]
 If environmental stresses leading to DNA damage were a persistent challenge to the survival of early microorganisms, then selection would likely have been continuous through the prokaryote to eukaryote transition,[60][70] and adaptative adjustments would have followed a course in which bacterial transformation or archaeal DNA transfer naturally gave rise to sexual reproduction in eukaryotes.
 Sex might also have been present even earlier, in the hypothesized RNA world that preceded DNA cellular life forms.[73] One proposed origin of sex in the RNA world was based on the type of sexual interaction that is known to occur in extant single-stranded segmented RNA viruses, such as influenza virus, and in extant double-stranded segmented RNA viruses such as reovirus.[74]
 Exposure to conditions that cause RNA damage could have led to blockage of replication and death of these early RNA life forms. Sex would have allowed re-assortment of segments between two individuals with damaged RNA, permitting undamaged combinations of RNA segments to come together, thus allowing survival. Such a regeneration phenomenon, known as multiplicity reactivation, occurs in the influenza virus[75] and reovirus.[76]
 Another theory is that sexual reproduction originated from selfish parasitic genetic elements that exchange genetic material (that is: copies of their own genome) for their transmission and propagation. In some organisms, sexual reproduction has been shown to enhance the spread of parasitic genetic elements (e.g. yeast, filamentous fungi).[77]
 Bacterial conjugation is a form of genetic exchange that some sources describe as ""sex"", but technically is not a form of reproduction, even though it is a form of horizontal gene transfer. However, it does support the ""selfish gene"" part theory, since the gene itself is propagated through the F-plasmid.[68]
 A similar origin of sexual reproduction is proposed to have evolved in ancient haloarchaea as a combination of two independent processes: jumping genes and plasmid swapping.[78]
 A third theory is that sex evolved as a form of cannibalism: One primitive organism ate another one, but instead of completely digesting it, some of the eaten organism's DNA was incorporated into the DNA of the eater.[68][66]
 Sex may also be derived from another prokaryotic process. A comprehensive theory called ""origin of sex as vaccination"" proposes that eukaryan sex-as-syngamy (fusion sex) arose from prokaryan unilateral sex-as-infection, when infected hosts began swapping nuclearised genomes containing coevolved, vertically transmitted symbionts that provided protection against horizontal superinfection by other, more virulent symbionts.
 Consequently, sex-as-meiosis (fission sex) would evolve as a host strategy for uncoupling from (and thereby render impotent) the acquired symbiotic/parasitic genes.[79]
 While theories positing fitness benefits that led to the origin of sex are often problematic,[citation needed] several theories addressing the emergence of the mechanisms of sexual reproduction have been proposed.
 The viral eukaryogenesis (VE) theory proposes that eukaryotic cells arose from a combination of a lysogenic virus, an archaean, and a bacterium. This model suggests that the nucleus originated when the lysogenic virus incorporated genetic material from the archaean and the bacterium and took over the role of information storage for the amalgam. The archaeal host transferred much of its functional genome to the virus during the evolution of cytoplasm, but retained the function of gene translation and general metabolism. The bacterium transferred most of its functional genome to the virus as it transitioned into a mitochondrion.[80]
 For these transformations to lead to the eukaryotic cell cycle, the VE hypothesis specifies a pox-like virus as the lysogenic virus. A pox-like virus is a likely ancestor because of its fundamental similarities with eukaryotic nuclei. These include a double stranded DNA genome, a linear chromosome with short telomeric repeats, a complex membrane bound capsid, the ability to produce capped mRNA, and the ability to export the capped mRNA across the viral membrane into the cytoplasm. The presence of a lysogenic pox-like virus ancestor explains the development of meiotic division, an essential component of sexual reproduction.[81]
 Meiotic division in the VE hypothesis arose because of the evolutionary pressures placed on the lysogenic virus as a result of its inability to enter into the lytic cycle. This selective pressure resulted in the development of processes allowing the viruses to spread horizontally throughout the population. The outcome of this selection was cell-to-cell fusion. (This is distinct from the conjugation methods used by bacterial plasmids under evolutionary pressure, with important consequences.)[80] The possibility of this kind of fusion is supported by the presence of fusion proteins in the envelopes of the pox viruses that allow them to fuse with host membranes. These proteins could have been transferred to the cell membrane during viral reproduction, enabling cell-to-cell fusion between the virus host and an uninfected cell. The theory proposes meiosis originated from the fusion between two cells infected with related but different viruses which recognised each other as uninfected. After the fusion of the two cells, incompatibilities between the two viruses result in a meiotic-like cell division.[81]
 The two viruses established in the cell would initiate replication in response to signals from the host cell. A mitosis-like cell cycle would proceed until the viral membranes dissolved, at which point linear chromosomes would be bound together with centromeres. The homologous nature of the two viral centromeres would incite the grouping of both sets into tetrads. It is speculated that this grouping may be the origin of crossing over, characteristic of the first division in modern meiosis. The partitioning apparatus of the mitotic-like cell cycle the cells used to replicate independently would then pull each set of chromosomes to one side of the cell, still bound by centromeres. These centromeres would prevent their replication in subsequent division, resulting in four daughter cells with one copy of one of the two original pox-like viruses. The process resulting from combination of two similar pox viruses within the same host closely mimics meiosis.[81]
 An alternative theory, proposed by Thomas Cavalier-Smith, was labeled the Neomuran revolution. The designation ""Neomuran revolution"" refers to the appearances of the common ancestors of eukaryotes and archaea. Cavalier-Smith proposes that the first neomurans emerged 850 million years ago. Other molecular biologists assume that this group appeared much earlier, but Cavalier-Smith dismisses these claims because they are based on the ""theoretically and empirically"" unsound model of molecular clocks. Cavalier-Smith's theory of the Neomuran revolution has implications for the evolutionary history of the cellular machinery for recombination and sex. It suggests that this machinery evolved in two distinct bouts separated by a long period of stasis; first the appearance of recombination machinery in a bacterial ancestor which was maintained for 3 Gy(billion years), until the neomuran revolution when the mechanics were adapted to the presence of nucleosomes. The archaeal products of the revolution maintained recombination machinery that was essentially bacterial, whereas the eukaryotic products broke with this bacterial continuity. They introduced cell fusion and ploidy cycles into cell life histories. Cavalier-Smith argues that both bouts of mechanical evolution were motivated by similar selective forces: the need for accurate DNA replication without loss of viability.[82]
 Some questions biologists have attempted to answer include:
"
https://en.wikipedia.org/wiki/Physics,Physics,"
 Physics is the natural science of matter, involving the study of matter,[a] its fundamental constituents, its motion and behavior through space and time, and the related entities of energy and force.[2] Physics is one of the most fundamental scientific disciplines, with its main goal being to understand how the universe behaves.[b][3][4][5] A scientist who specializes in the field of physics is called a physicist.
 Physics is one of the oldest academic disciplines and, through its inclusion of astronomy, perhaps the oldest.[6] Over much of the past two millennia, physics, chemistry, biology, and certain branches of mathematics were a part of natural philosophy, but during the Scientific Revolution in the 17th century these natural sciences emerged as unique research endeavors in their own right.[c] Physics intersects with many interdisciplinary areas of research, such as biophysics and quantum chemistry, and the boundaries of physics are not rigidly defined. New ideas in physics often explain the fundamental mechanisms studied by other sciences[3] and suggest new avenues of research in these and other academic disciplines such as mathematics and philosophy.
 Advances in physics often enable advances in new technologies. For example, advances in the understanding of electromagnetism, solid-state physics, and nuclear physics led directly to the development of new products that have dramatically transformed modern-day society, such as television, computers, domestic appliances, and nuclear weapons;[3] advances in thermodynamics led to the development of industrialization; and advances in mechanics inspired the development of calculus.
"
https://en.wikipedia.org/wiki/Classical_physics,Classical physics,"Classical physics is a group of physics theories that predate modern, more complete, or more widely applicable theories. If a currently accepted theory is considered to be modern, and its introduction represented a major paradigm shift, then the previous theories, or new theories based on the older paradigm, will often be referred to as belonging to the area of ""classical physics"".
 As such, the definition of a classical theory depends on context. Classical physical concepts are often used when modern theories are unnecessarily complex for a particular situation. Most often, classical physics refers to pre-1900 physics, while modern physics refers to post-1900 physics, which incorporates elements of quantum mechanics and relativity.[1]
"
https://en.wikipedia.org/wiki/Applied_physics,Applied physics,"Applied physics is the application of physics to solve scientific or engineering problems. It is usually considered to be a bridge or a connection between physics and engineering.
""Applied"" is distinguished from ""pure"" by a subtle combination of factors, such as the motivation and attitude of researchers and the nature of the relationship to the technology or science that may be affected by the work. Applied physics is rooted in the fundamental truths and basic concepts of the physical sciences, but is concerned with the utilization of scientific principles in practical devices and systems, and in the application of physics in other areas of science and high technology.[1]
"
https://en.wikipedia.org/wiki/Theoretical_physics,Theoretical physics,"
 Theoretical physics is a branch of physics that employs mathematical models and abstractions of physical objects and systems to rationalize, explain and predict natural phenomena. This is in contrast to experimental physics, which uses experimental tools to probe these phenomena.
 The advancement of science generally depends on the interplay between experimental studies and theory. In some cases, theoretical physics adheres to standards of mathematical rigour while giving little weight to experiments and observations.[a] For example, while developing special relativity, Albert Einstein was concerned with the Lorentz transformation which left Maxwell's equations invariant, but was apparently uninterested in the Michelson–Morley experiment on Earth's drift through a luminiferous aether.[1] Conversely, Einstein was awarded the Nobel Prize for explaining the photoelectric effect, previously an experimental result lacking a theoretical formulation.[2]
"
https://en.wikipedia.org/wiki/Experimental_physics,Experimental physics,"Experimental physics is the category of disciplines and sub-disciplines in the field of physics that are concerned with the observation of physical phenomena and experiments. Methods vary from discipline to discipline, from simple experiments and observations, such as Galileo's experiments, to more complicated ones, such as the Large Hadron Collider.
"
https://en.wikipedia.org/wiki/Isaac_Newton,Isaac Newton,"
 Sir Isaac Newton FRS (25 December 1642 – 20 March 1726/27)[a] was an English mathematician, physicist, astronomer, alchemist, theologian, and author who was described in his time as a natural philosopher. He was a key figure in the Scientific Revolution and the Enlightenment that followed. His pioneering book Philosophiæ Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy), first published in 1687, consolidated many previous results and established classical mechanics.[17][18] Newton also made seminal contributions to optics, and shares credit with German mathematician Gottfried Wilhelm Leibniz for developing infinitesimal calculus.
 In the Principia, Newton formulated the laws of motion and universal gravitation that formed the dominant scientific viewpoint for centuries until it was superseded by the theory of relativity. Newton used his mathematical description of gravity to derive Kepler's laws of planetary motion, account for tides, the trajectories of comets, the precession of the equinoxes and other phenomena, eradicating doubt about the Solar System's heliocentricity. He demonstrated that the motion of objects on Earth and celestial bodies could be accounted for by the same principles. Newton's inference that the Earth is an oblate spheroid was later confirmed by the geodetic measurements of Maupertuis, La Condamine, and others, convincing most European scientists of the superiority of Newtonian mechanics over earlier systems.
 Newton built the first practical reflecting telescope and developed a sophisticated theory of colour based on the observation that a prism separates white light into the colours of the visible spectrum. His work on light was collected in his highly influential book Opticks, published in 1704. He also formulated an empirical law of cooling, made the first theoretical calculation of the speed of sound, and introduced the notion of a Newtonian fluid. In addition to his work on calculus, as a mathematician Newton contributed to the study of power series, generalised the binomial theorem to non-integer exponents, developed a method for approximating the roots of a function, and classified most of the cubic plane curves.
 Newton was a fellow of Trinity College and the second Lucasian Professor of Mathematics at the University of Cambridge. He was a devout but unorthodox Christian who privately rejected the doctrine of the Trinity. He refused to take holy orders in the Church of England, unlike most members of the Cambridge faculty of the day. Beyond his work on the mathematical sciences, Newton dedicated much of his time to the study of alchemy and biblical chronology, but most of his work in those areas remained unpublished until long after his death. Politically and personally tied to the Whig party, Newton served two brief terms as Member of Parliament for the University of Cambridge, in 1689–1690 and 1701–1702. He was knighted by Queen Anne in 1705 and spent the last three decades of his life in London, serving as Warden (1696–1699) and Master (1699–1727) of the Royal Mint, as well as president of the Royal Society (1703–1727).
"
https://en.wikipedia.org/wiki/Thermodynamics,Thermodynamics,"
 
 Thermodynamics is a branch of physics that deals with heat, work, and temperature, and their relation to energy, entropy, and the physical properties of matter and radiation. The behavior of these quantities is governed by the four laws of thermodynamics which convey a quantitative description using measurable macroscopic physical quantities, but may be explained in terms of microscopic constituents by statistical mechanics. Thermodynamics applies to a wide variety of topics in science and engineering, especially physical chemistry, biochemistry, chemical engineering and mechanical engineering, but also in other complex fields such as meteorology.
 Historically, thermodynamics developed out of a desire to increase the efficiency of early steam engines, particularly through the work of French physicist Sadi Carnot (1824) who believed that engine efficiency was the key that could help France win the Napoleonic Wars.[1] Scots-Irish physicist Lord Kelvin was the first to formulate a concise definition of thermodynamics in 1854[2] which stated, ""Thermo-dynamics is the subject of the relation of heat to forces acting between contiguous parts of bodies, and the relation of heat to electrical agency.""  German physicist and mathematician Rudolf Clausius restated Carnot's principle known as the Carnot cycle and gave so the theory of heat a truer and sounder basis. His most important paper, ""On the Moving Force of Heat"",[3] published in 1850, first stated the second law of thermodynamics. In 1865 he introduced the concept of entropy. In 1870 he introduced the virial theorem, which applied to heat.[4]
 The initial application of thermodynamics to mechanical heat engines was quickly extended to the study of chemical compounds and chemical reactions. Chemical thermodynamics studies the nature of the role of entropy in the process of chemical reactions and has provided the bulk of expansion and knowledge of the field. Other formulations of thermodynamics emerged. Statistical thermodynamics, or statistical mechanics, concerns itself with statistical predictions of the collective motion of particles from their microscopic behavior. In 1909, Constantin Carathéodory presented a purely mathematical approach in an axiomatic formulation, a description often referred to as geometrical thermodynamics.
"
https://en.wikipedia.org/wiki/Newton%27s_laws_of_motion,Newton's laws of motion,"
 Newton's laws of motion are three basic laws of classical mechanics that describe the relationship between the motion of an object and the forces acting on it. These laws can be paraphrased as follows:
 The three laws of motion were first stated by Isaac Newton in his Philosophiæ Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy), originally published in 1687.[3] Newton used them to investigate and explain the motion of many physical objects and systems, which laid the foundation for classical mechanics. In the time since Newton, the conceptual content of classical physics has been reformulated in alternative ways, involving different mathematical approaches that have yielded insights which were obscured in the original, Newtonian formulation. Limitations to Newton's laws have also been discovered; new theories are necessary when objects move at very high speeds (special relativity), are very massive (general relativity), or are very small (quantum mechanics).
"
https://en.wikipedia.org/wiki/Albert_Einstein,Albert Einstein,"
 Albert Einstein (/ˈaɪnstaɪn/ EYEN-styne;[4] German: [ˈalbɛʁt ˈʔaɪnʃtaɪn] (listen); 14 March 1879 – 18 April 1955) was a German-born theoretical physicist,[5] widely acknowledged to be one of the greatest and most influential physicists of all time. Best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics. Relativity and quantum mechanics are the two pillars of modern physics.[1][6] His mass–energy equivalence formula E = mc2, which arises from relativity theory, has been dubbed ""the world's most famous equation"".[7] His work is also known for its influence on the philosophy of science.[8][9] He received the 1921 Nobel Prize in Physics ""for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect"",[10] a pivotal step in the development of quantum theory. His intellectual achievements and originality resulted in ""Einstein"" becoming synonymous with ""genius"".[11] Einsteinium, one of the synthetic elements in the periodic table, was named in his honor.[12]
 In 1905, a year sometimes described as his annus mirabilis ('miracle year'), Einstein published four groundbreaking papers.[13] These outlined the theory of the photoelectric effect, explained Brownian motion, introduced special relativity, and demonstrated mass–energy equivalence. He thought that the laws of classical mechanics could no longer be reconciled with those of the electromagnetic field, which led him to develop his special theory of relativity. He then extended the theory to gravitational fields; he published a paper on general relativity in 1916, introducing his theory of gravitation. In 1917, he applied the general theory of relativity to model the structure of the universe.[14][15] He continued to deal with problems of statistical mechanics and quantum theory, which led to his explanations of particle theory and the motion of molecules. He also investigated the thermal properties of light and the quantum theory of radiation, which laid the foundation of the photon theory of light.
 However, for much of the later part of his career, he worked on two ultimately unsuccessful endeavors. First, despite his great contributions to quantum mechanics, he opposed what it evolved into, objecting that ""God does not play dice"".[16] Second, he attempted to devise a unified field theory by generalizing his geometric theory of gravitation to include electromagnetism. As a result, he became increasingly isolated from the mainstream of modern physics.
 Einstein was born in the German Empire, but moved to Switzerland in 1895, forsaking his German citizenship (as a subject of the Kingdom of Württemberg)[note 1] the following year. In 1897, at the age of 17, he enrolled in the mathematics and physics teaching diploma program at the Swiss Federal polytechnic school in Zürich, graduating in 1900. In 1901, he acquired Swiss citizenship, which he kept for the rest of his life, and in 1903, he secured a permanent position at the Swiss Patent Office in Bern. In 1905, he was awarded a PhD by the University of Zurich. In 1914, he moved to Berlin in order to join the Prussian Academy of Sciences and the Humboldt University of Berlin. In 1917, he became director of the Kaiser Wilhelm Institute for Physics; he also became a German citizen again, this time Prussian.
 In 1933, while he was visiting the United States, Adolf Hitler came to power in Germany. Einstein objected to the policies of the newly elected Nazi government;[17] he settled in the United States and became an American citizen in 1940.[18] On the eve of World War II, he endorsed a letter to President Franklin D. Roosevelt alerting him to the potential German nuclear weapons program and recommending that the US begin similar research. Einstein supported the Allies but generally denounced the idea of nuclear weapons.[19]
"
https://en.wikipedia.org/wiki/Classical_electromagnetism,Classical electromagnetism,"Classical electromagnetism or classical electrodynamics is a branch of theoretical physics that studies the interactions between electric charges and currents using an extension of the classical Newtonian model; It is, therefore, a classical field theory. The theory provides a description of electromagnetic phenomena whenever the relevant length scales and field strengths are large enough that quantum mechanical effects are negligible. For small distances and low field strengths, such interactions are better described by quantum electrodynamics, which is a quantum field theory.
 Fundamental physical aspects of classical electrodynamics are presented in many texts, such as those by Richard Feynman, Robert B. Leighton and Matthew Sands,[1] David J. Griffiths,[2] Wolfgang K. H. Panofsky and Melba Phillips,[3] and John David Jackson.[4]
"
